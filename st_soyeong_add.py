# module/package
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px #ÏùºÎã® Ïù¥Í±∞ Ïù¥Ïö©Ìï¥ Í∏∞Î≥∏ Í∑∏ÎûòÌîÑ Í∑∏Î¶º
import nltk 
import random
import plotly.graph_objects as go 
import urllib.request

from PIL import Image
from bs4 import BeautifulSoup
from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag

nltk.download('omw-1.4')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
nltk.download('wordnet')


# set-page
st.set_page_config(page_icon="üóΩ",
                   page_title="Îç∞Ïù¥ÌÑ∞Ï†ÄÎÑêÎ¶¨Ï¶ò-2Ï°∞")
add_radio = st.sidebar.radio("Table of Contents", ("üìÖ ÎØ∏Íµ≠Ïùò ÌòêÏò§ Î≤îÏ£Ñ, 2015ÎÖÑÎ∂ÄÌÑ∞ 2020ÎÖÑÍπåÏßÄ", "üö´ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, Ï¢Ä Îçî ÏûêÏÑ∏Ìûà ÏïåÏïÑÎ≥ºÍπå?", "üîçÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, ÏßÄÏó≠ÏúºÎ°ú Ï¢ÅÌòÄ Î≥¥Ïûê!", "üìà Ìä∏ÎüºÌîÑ Îì±Ïû•! ÌòêÏò§ Î≤îÏ£ÑÎèÑ ÏÉÅÏäπ?"))

# header
st.markdown("""
# ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, ÌôïÏÇ∞Í≥º Ïã¨Ìôî: ÏΩîÎ°úÎÇò19 Ï†ÑÌõÑ ÎØ∏Íµ≠Ïùò ÌòêÏò§ Î≤îÏ£ÑÎ•º Ï°∞Î™ÖÌïòÎã§üí°
* Îç∞Ïù¥ÌÑ∞Ï†ÄÎÑêÎ¶¨Ï¶ò: Ïò§ÏÜåÏòÅ, Ïù¥ÌòúÏ†ï, ÏµúÎã§Ïó∞
""") 

# introduce
st.error('''
‚ùìÏΩîÎ°úÎÇò19Îäî ÎØ∏Íµ≠ÏóêÏÑú ÏùºÏñ¥ÎÇòÎäî ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏóê Ïñ¥Îñ§ ÏòÅÌñ•ÏùÑ ÎØ∏Ï≥§ÏùÑÍπå?

   ‚úÖ2019ÎÖÑÍ≥º 2020ÎÖÑÏùò ÌòêÏò§ Î≤îÏ£Ñ Í±¥Ïàò, Í≥ºÍ≤©ÏÑ±, Í≥µÍ∞úÏÑ± ÎπÑÍµêÌïòÍ∏∞
    
‚ùìÏΩîÎ°úÎÇò19 ÌîºÌï¥Í∞Ä Ïã¨ÌñàÎçò Ï£ºÏóêÏÑúÎäî ÌòêÏò§ Î≤îÏ£ÑÎèÑ Ïã¨ÌñàÏùÑÍπå?

   ‚úÖÏΩîÎ°úÎÇò19 ÌôïÏßÑÏûê/ÏÇ¨ÎßùÏûê Ïàò ÏÉÅÏúÑ 10Í∞ú Ï£ºÏôÄ ÌïòÏúÑ 10Í∞ú Ï£º Î≤îÏ£Ñ ÏñëÏÉÅ Îì§Ïó¨Îã§ Î≥¥Í∏∞

‚ùìÌä∏ÎüºÌîÑÏùò Îì±Ïû•Ïù¥ ÌòêÏò§ Î≤îÏ£Ñ ÏñëÏÉÅÏóê Í∞ÄÏ†∏Ïò® Î≥ÄÌôîÎäî?

   ‚úÖÎØ∏Íµ≠ Íµ≠Ï†ïÏó∞ÏÑ§ ÌÇ§ÏõåÎìú Î∂ÑÏÑùÌïòÍ∏∞
           ''')   
 
st.text_area('data', '''Raw data: 
CNN Politics State of the Union: 2017 ~ 2021,
The Hate Crime Statistics Program of the FBI Uniform Crime Reporting (UCR) Program
             ''', label_visibility = "hidden") 

st.markdown("""
----------------
""")

fbi =  pd.read_csv("fbi_data_edited.csv", low_memory=False)
df = pd.DataFrame(fbi, columns=['DATA_YEAR', 'BIAS_DESC'])


if add_radio == "üìÖ ÎØ∏Íµ≠Ïùò ÌòêÏò§ Î≤îÏ£Ñ, 2015ÎÖÑÎ∂ÄÌÑ∞ 2020ÎÖÑÍπåÏßÄ":
  # section1
  st.markdown("""
  ## üìÖ ÎØ∏Íµ≠Ïùò ÌòêÏò§ Î≤îÏ£Ñ, 2015ÎÖÑÎ∂ÄÌÑ∞ 2020ÎÖÑÍπåÏßÄ
  """)

  st.markdown('''
              #
              ''')

  st.subheader("Ï†êÏ†ê Ï¶ùÍ∞ÄÌïòÎäî ÌòêÏò§ Î≤îÏ£Ñ Î∞úÏÉù Í±¥Ïàò")



  # section1-1: Ï†ÑÏ≤¥ÌòêÏò§/ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£Ñ

  #Anti Asian Ï¶ùÍ∞ÄÎßå Î≥¥Ïó¨Ï£ºÎäî Í∑∏ÎûòÌîÑ
  options_2 = st.radio('ÏòµÏÖòÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî', ['Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£Ñ', 'ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£Ñ'])
  df_2015 = df[(df['DATA_YEAR'] == 2015)]
  df_2016 = df[(df['DATA_YEAR'] == 2016)]
  df_2017 = df[(df['DATA_YEAR'] == 2017)]
  df_2018 = df[(df['DATA_YEAR'] == 2018)]
  df_2019 = df[(df['DATA_YEAR'] == 2019)]
  df_2020 = df[(df['DATA_YEAR'] == 2020)]

  #ÏÉàÎ°úÏö¥ df: Ïó∞ÎèÑÎ≥Ñ Ï†ÑÏ≤¥ / ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§Î≤îÏ£Ñ count. index: Ïó∞ÎèÑ, columns: Í∞í
  #Ï†ÑÏ≤¥
  all_hates = [len(df_2015['BIAS_DESC']), len(df_2016['BIAS_DESC']), len(df_2017['BIAS_DESC']), len(df_2018['BIAS_DESC']),
              len(df_2019['BIAS_DESC']), len(df_2020['BIAS_DESC'])]
  df_all = pd.DataFrame(all_hates, index = ['2015', '2016', '2017', '2018', '2019', '2020'])

  all_fig = px.line(df_all, title = "All Hate Crime Cases in the US", markers=True)
  all_fig.update_layout(xaxis = dict({"title" : "Year"}), yaxis = dict({"title" : "Counted Cases"}), showlegend = False)

  #ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§Î≤îÏ£Ñ

  asian_hates = [len(df_2015.loc[df_2015['BIAS_DESC'] == 'Anti-Asian']), len(df_2016.loc[df_2016['BIAS_DESC'] == 'Anti-Asian']), 
              len(df_2017.loc[df_2017['BIAS_DESC'] == 'Anti-Asian']), len(df_2018.loc[df_2018['BIAS_DESC'] == 'Anti-Asian']),
              len(df_2019.loc[df_2019['BIAS_DESC'] == 'Anti-Asian']), len(df_2020.loc[df_2020['BIAS_DESC'] == 'Anti-Asian'])]
  df_asian_edit = pd.DataFrame(asian_hates, index = ['2015', '2016', '2017', '2018', '2019', '2020'])
  asian_fig = px.line(df_asian_edit, title = "Asian Hate Crime Cases in the US", markers=True)
  asian_fig.update_layout(xaxis = dict({"title" : "Year"}), yaxis = dict({"title" : "Counted Cases"}), showlegend = False)

  if options_2 == 'Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£Ñ':
      st.plotly_chart(all_fig)
  elif options_2 == 'ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£Ñ':
      st.plotly_chart(asian_fig)

  st.info('''
  * Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£Ñ Íæ∏Ï§ÄÌûà Ï¶ùÍ∞Ä: ÎØ∏Íµ≠ Ï†ÑÏó≠Ïùò ÌòêÏò§ Î≤îÏ£Ñ ÎπàÎèÑÏàòÎ•º ÏãúÍ∞ÅÌôîÌïú Í≤∞Í≥º, 2015ÎÖÑÎ∂ÄÌÑ∞ 2020ÎÖÑÍπåÏßÄ Ï¶ùÍ∞ÄÌïòÍ≥† ÏûàÎäî Î™®ÏäµÏùÑ Î≥º Ïàò ÏûàÏñ¥Ïöî. 
  * Î¨¥ÏóáÏù¥ Í∏∞Ï†ê?: Ìä∏ÎüºÌîÑ Ï†Ñ ÎåÄÌÜµÎ†πÏùò ÎãπÏÑ†Ïù¥ ÌôïÏ†ïÎêú 2016ÎÖÑ, ÏΩîÎ°úÎÇò19Í∞Ä Î∞úÏÉùÌïú 2020ÎÖÑÏùÑ Í∏∞Ï†êÏúºÎ°ú ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÍ∞Ä ÎëêÎìúÎü¨ÏßÄÍ≤å Ï¶ùÍ∞ÄÌñàÏñ¥Ïöî! 
               ''')

  st.markdown('''
              #
              ''')
  # section1-2: Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£Ñ ÎåÄÎπÑ ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£Ñ ÎπÑÏú® + Îß§Ìä∏Î¶≠Ïä§

  all_asian_ratio = []
  for i in range(len(asian_hates)):
      all_asian_ratio.append((int(asian_hates[i]) / int(all_hates[i])) * 100) #ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§Î≤îÏ£Ñ Í±¥Ïàò / Ï†ÑÏ≤¥ ÌòêÏò§Î≤îÏ£Ñ Í±¥Ïàò * 100 : ÎπÑÏú® (ÎßûÎÇò?)

  df_compare = pd.DataFrame(all_asian_ratio, index = ['2015', '2016', '2017', '2018', '2019', '2020'])
  compare_fig = px.bar(df_compare, title = "Asian Hate Crime Cases Ratio Out of All Hate Crimes")
  compare_fig.update_layout(xaxis = dict({"title" : "Year"}), yaxis = dict({"title" : "Relatvie proportion(%)"}), showlegend = False)

  cols = st.columns((1, 1, 3))


  cols[0].metric("","", "")
  cols[0].write("Crime Cases")
  cols[0].metric("2019", "188", "11.5%")
  cols[0].metric("","", "")
  cols[0].write("Crime Proportion")
  cols[0].metric("2019", "2.38%", "0.3%p")

  cols[1].metric("","", "")
  cols[1].metric("","", "")
  cols[1].metric("2020", "323", "26.4%")
  cols[1].metric("","", "")
  cols[1].metric("","", "")
  cols[1].metric("2020", "3.14%", "0.76%p")

  cols[2].plotly_chart(compare_fig, use_container_width = True)


  st.info('''
  * ‚ÄòÏΩîÏãúÍµ≠‚ÄôÏùò ÎèÑÎûò: ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ ÎπàÎèÑÏàòÎäî ÌïúÎ≤àÎèÑ Í∫æÏù¥ÏßÄ ÏïäÍ≥† ÏÉÅÏäπÏÑ∏Ïóê ÏûàÏóàÎäîÎç∞Ïöîüìà
  ÌäπÌûà Ìå¨Îç∞ÎØπÏù¥ ÏãúÏûëÎêú 2020ÎÖÑÏùò ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÎäî Ï†ÑÎÖÑÎèÑ ÎåÄÎπÑ 55% Ï¶ùÍ∞ÄÌñàÏäµÎãàÎã§. 5ÎÖÑ Ï†ÑÏù∏ 2015ÎÖÑÏóê ÎπÑÍµêÌñàÏùÑ ÎïåÎäî 283% Í∞ÄÎüâ Ï¶ùÍ∞ÄÌïú ÏàòÏπòÏóêÏöî.
   ÎèôÏùºÌïú Í∏∞Í∞Ñ Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£ÑÎäî 30% Ï¶ùÍ∞ÄÌïú Í≤ÉÍ≥º ÎπÑÍµêÌï¥ÎèÑ ÏóÑÏ≤≠ÎÇú Î≥ÄÌôîÏ£†? 
          ''')    

  st.markdown('''
              #
              #
              ''')

  # section1-3: ÏõêÍ∑∏ÎûòÌîÑ
  st.subheader("ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò ÎπÑÏ§ëÏùÄ Ïñ¥ÎñªÍ≤å Î≥ÄÌôîÌñàÏùÑÍπå?")

  tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["2015", "2016", "2017", "2018", "2019", "2020"])

  @st.cache
  def crime_pie_chart(filename):
      crime_data_count = pd.read_csv(filename)
      crime_data_count['number'].astype(int)
      cdc_2015 = crime_data_count['number'].tolist() #ÎåÄÏÉÅ Ïù∏Ï¢ÖÎ≥Ñ Î≤îÏ£ÑÏàò Îã¥ÏùÄ Î¶¨Ïä§Ìä∏.
      idx_2015 = list(crime_data_count['race'])

      return crime_data_count


  with tab1:
      st.header("2015")
      fig_2015 = px.pie(crime_pie_chart("hate_crime_race.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2015.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2015)

  with tab2:
      st.header("2016")
      fig_2016 = px.pie(crime_pie_chart("hate_crime_race_2016.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2016.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2016)


  with tab3:
      st.header("2017")
      fig_2017 = px.pie(crime_pie_chart("hate_crime_race_2017.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2017.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2017)

  with tab4:
      st.header("2018")
      fig_2018 = px.pie(crime_pie_chart("hate_crime_race_2018.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2018.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2018)


  with tab5:
      st.header("2019")
      fig_2019 = px.pie(crime_pie_chart("hate_crime_race_2019.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2019.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2019)

  with tab6:
      st.header("2020")
      fig_2020 = px.pie(crime_pie_chart("hate_crime_race_2020.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2020.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2020)

  st.caption('*ÌäπÏ†ï ÎåÄÏÉÅÏùÑ Ìñ•Ìïú ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä 50Í±¥ Ïù¥Ìïò Î∞úÏÉùÌïú Í≤ΩÏö∞Îäî Í∏∞ÌÉÄÎ°ú ÌÜµÌï©')

  st.info("""
  * Îß§ÎÖÑ 100Í±¥ Ïù¥ÏÉÅ Î∞úÏÉù: ÎØ∏Íµ≠ Ï†ÑÏó≠Ïùò ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÎ•º ÌîºÌï¥ÎåÄÏÉÅ(victims)Î≥ÑÎ°ú Î∂ÑÎ•òÌï¥Î¥§ÎçîÎãà,ÏïÑÏãúÏïÑÏù∏ÏùÑ ÎåÄÏÉÅÏúºÎ°ú ÌïòÎäî ÌòêÏò§ Î≤îÏ£ÑÎäî 2015ÎÖÑÎ∂ÄÌÑ∞ 2020ÎÖÑÍπåÏßÄ Îß§ÎÑå 100Í±¥ ÎÑòÍ≤å Î∞úÏÉùÌñàÏñ¥Ïöî. Í∞àÏàòÎ°ù Í±¥Ïàò, ÎπÑÏ§ë Î™®Îëê ÎäòÏñ¥ÎÇòÍ≥† ÏûàÎäî Î™®ÏäµÏùÑ Î≥¥Ïù¥ÎÑ§Ïöî.
  * 2020ÎÖÑ Ïó≠ÎåÄ ÏµúÍ≥†Ïπò: ÌäπÌûà ÏΩîÎ°úÎÇò19Í∞Ä Î∞úÏÉùÌïú 2020ÎÖÑ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÎäî Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£Ñ Ï§ë 3.13%Î•º Ï∞®ÏßÄÌïòÎ©∞ ÏµúÍ≥†ÏπòÎ•º Í∏∞Î°ùÌñàÏñ¥Ïöî. 
  """)

  st.markdown('''
              #
  --------
  #
              ''')



elif add_radio == "üö´ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, Ï¢Ä Îçî ÏûêÏÑ∏Ìûà ÏïåÏïÑÎ≥ºÍπå?":
  # section2
  st.markdown("""
  ##  üö´ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, Ï¢Ä Îçî ÏûêÏÑ∏Ìûà ÏïåÏïÑÎ≥ºÍπå?
  """)

  st.subheader("Ïö∞Î¶¨Îäî Î≤îÏ£ÑÏùò Ïã¨Í∞ÅÏÑ±ÏùÑ ÏïÑÎûòÏùò ÏÑ∏ Ï≤ôÎèÑÎ°ú ÌôïÏù∏ÌñàÏñ¥Ïöîüí°")

  st.success('''
  üìå Î≤îÏ£Ñ ÎπàÎèÑÏàò

  üìå (Î≤îÏ£Ñ Ïú†ÌòïÏóê Îî∞Îùº)Í≥ºÍ≤©ÏÑ±

  üìå (Î≤îÏ£Ñ Ïû•ÏÜå)Í≥µÍ∞úÏÑ±
             ''')



  # section2-1 : ÌûàÌä∏Îßµ
  st.subheader("ÏõîÎ≥Ñ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í±¥Ïàò")

  df1 = pd.DataFrame(fbi, columns=['DATA_YEAR', 'INCIDENT_DATE', 'OFFENSE_NAME', 'BIAS_DESC', 'LOCATION_NAME']) 
  df1 = df1[df1['BIAS_DESC'].str.contains('Anti-Asian', na = False)]     ## Anti-Asian
  df1 = df1[(df1['DATA_YEAR'] >= 2015)]      ## Ïó∞ÎèÑÎ≥ÑÎ°ú Î≥¥Í∏∞ ÏúÑÌï¥ 2016(Ìä∏ÎüºÌîÑ ÎãπÏÑ† Ïó∞ÎèÑÎ∂ÄÌÑ∞: Ï†ÑÌõÑÎπÑÍµê ÎäêÎÇå)

  df1['INCIDENT_DATE'] = pd.to_datetime(df1['INCIDENT_DATE'])

  #Ïó∞ÎèÑ-Îã¨ Ïª¨Îü¨Îßµ
  #Í∞Å Ïó∞ÎèÑ Í∏∞Ï§ÄÏúºÎ°ú, Îã¨Î≥ÑÎ°ú Î≤îÏ£Ñ Í±¥Ïàò Ïπ¥Ïö¥Ìä∏Ìï¥ÏÑú Ï†ÄÏû•. Ïù¥ÌõÑ Ïª¨Îü¨Îßµ Í∑∏Î¶¨Í∏∞
  df1['INCIDENT_DATE'] = pd.to_datetime(df1['INCIDENT_DATE'])

  @st.cache
  def count_monthly_crime(year_num):
      cases = []
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-01-01', f'{year_num}-01-31')])) #1Ïõî - ÏàúÏÑúÎûë ÎÇ†Ïßú ÎßûÏ∂îÎ†§Í≥† ÏùºÏùºÌûà ÌñàÏùå
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-02-01', f'{year_num}-02-28')])) #2Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-03-01', f'{year_num}-03-31')])) #3Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-04-01', f'{year_num}-04-30')])) #4Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-05-01', f'{year_num}-05-31')])) #5Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-06-01', f'{year_num}-06-30')])) #6Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-07-01', f'{year_num}-07-31')])) #7Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-08-01', f'{year_num}-08-30')])) #8Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-09-01', f'{year_num}-09-30')])) #9Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-10-01', f'{year_num}-10-31')])) #10Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-11-01', f'{year_num}-11-30')])) #11Ïõî
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-12-01', f'{year_num}-12-31')])) #12Ïõî
      return cases

  monthly_crime = [count_monthly_crime(2015), count_monthly_crime(2016), count_monthly_crime(2017), count_monthly_crime(2018), count_monthly_crime(2019), count_monthly_crime(2020)]

  month_name = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
  year_month_colormap = px.imshow(monthly_crime,
                  labels=dict(x="Months", y="Year", color="Cases", width=500, height=700), 
                  x = month_name,
                  y = ['2015', '2016', '2017', '2018', '2019', '2020'],
                  color_continuous_scale='Reds',
                  width = 800, height = 600)


  st.markdown("##### Asian Hate Crimes Cases (2015-2020)")
  st.plotly_chart(year_month_colormap, use_container_width = True)


  st.info('''
  * 2020ÎÖÑ 3Ïõî, Ï†ÄÍ≤å Î≠êÏïº?: 2016ÎÖÑ ÎåÄÏÑ†Ïù¥ ÏûàÏóàÎçò 11Ïõî ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä ÏÜåÌè≠ Ï¶ùÍ∞ÄÌïú ÏñëÏÉÅÏùÑ Î≥¥Ïù¥Î©∞, Ïù¥ÌõÑ Í∞ÑÌóêÏ†ÅÏúºÎ°ú Î∞úÏÉù ÎπàÎèÑÍ∞Ä ÎÜíÏïÑÏßÄÎçò ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÎäî 2020ÎÖÑ ÏΩîÎ°úÎÇò19Í∞Ä Ï∞ΩÍ∂êÌïòÎçò ÏãúÍ∏∞ Ï†ïÏ†êÏùÑ Ï∞çÏóàÏñ¥Ïöî.
  ÎØ∏Íµ≠Ïóê ÏΩîÎ°úÎÇò19Í∞Ä Îßâ ÏÉÅÎ•ôÌï¥ Í∏∞ÏäπÏùÑ Î∂ÄÎ¶¨Îçò 3ÏõîÍ≥º 4ÏõîÏùò ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÎäî Í∞ÅÍ∞Å 52Í±¥ÏúºÎ°ú,
  Ïù¥Ï†Ñ ÏµúÎã§Î∞úÏÉù ÏõîÏù∏ 2019ÎÖÑ 12ÏõîÏùò 22Í±¥Î≥¥Îã§ÎèÑ 2.5Î∞∞Í∞ÄÎüâ ÎÜíÏùÄ ÏàòÏπòÏóêÏöî!
  Í∞ôÏùÄ Ìï¥ 10ÏõîÍπåÏßÄ ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÎäî Îß§Ïõî 20Í±¥ Ïù¥ÏÉÅÏúºÎ°ú Ïú†Î°ÄÏóÜÎäî Î∞úÏÉù ÌòÑÌô©ÏùÑ Î≥¥ÏòÄÏäµÎãàÎã§üö® 
          ''')

  st.markdown('''
              #
  #
              ''')



  # section2-2 : Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±: ÎùºÏù∏, ÎßâÎåÄ
  st.subheader("ÌòêÏò§ Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±, ÏΩîÎ°úÎÇò19 Ï†ÑÌõÑÎ•º Î≥ºÍπå?")

  st.success('''
  Í≥ºÍ≤©ÏÑ±ÏùÄ Ïã†Ï≤¥Ïóê ÏßÅÏ†ëÏ†ÅÏúºÎ°ú Í∞ÄÌï¥ÏßÄÎäî ÏúÑÌï¥ Ï†ïÎèÑÎ•º Îî∞Ï†∏, Î≤îÏ£Ñ Ï¢ÖÎ•òÏùò ÏúÑÌï¥ÏÑ±Ïù¥ ÎÜíÏùÑÏàòÎ°ù 4Ïóê Í∞ÄÍπùÍ≤å Î∂ÑÎ•òÌñàÏäµÎãàÎã§. ÎØ∏Íµ≠ Î≥¥ÌÜµÎ≤ï Í∏∞Ï§Ä Í≤ΩÎ≤îÏ£ÑÏôÄ Ï§ëÎ≤îÏ£Ñ Î∂ÑÎ•òÎ•º Ï∞∏Í≥†ÌñàÏùÑ Îïå, ÎåÄÏ≤¥Î°ú 1 ~ 2Ïóê Ìï¥ÎãπÌïòÎäî Î≤îÏ£ÑÎäî Í≤ΩÎ≤îÏ£Ñ, 3 ~ 4Ïóê Ìï¥ÎãπÌïòÎäî Î≤îÏ£ÑÎäî Ï§ëÎ≤îÏ£ÑÎ°ú Î∂ÑÎ•òÎê©ÎãàÎã§.

  * 1 = ÌòëÎ∞ï(intimidation), Î¨∏ÏÑú ÏúÑÏ°∞(counterfeiting/forgery), ÏïΩÎ¨º ÏÜåÏßÄ Î∞è ÌïôÍµêÏóê Îì§Í≥† Í∞ê(Drug violations), Î¨¥Í∏∞ ÏÜåÏßÄ Î∞è ÌïôÍµêÏóê Îì§Í≥† Í∞ê(Weapon Law Violation)\n
  * 2 = Ï†àÎèÑ(theft), Ïû¨Î¨ºÏÜêÍ¥¥(destruction/damage/vandalism of property), Í∏∞ÌÉÄ Ï†àÎèÑ(all other larceny)\n
  * 3 = Ìè≠Ìñâ(assault), Í∞ïÎèÑ(robbery), Ï£ºÍ±∞Ïπ®ÏûÖÍ∞ïÎèÑ(burglary/breaking & entering), Î∞©Ìôî(arson)\n
  * 4 = Í∞ïÍ∞Ñ(rape), Ïú†Í¥¥(Kidnapping), ÏÇ¥Ïù∏¬∑Í≥ºÏã§ÏπòÏÇ¨¬∑Î™®ÏÇ¥(murder and nonnegligent manslaughter)\n
             ''')

  df1 = pd.DataFrame(fbi, columns=['DATA_YEAR', 'INCIDENT_DATE', 'OFFENSE_NAME', 'BIAS_DESC', 'LOCATION_NAME']) #ÌòúÏ†ïÏù¥Í∞Ä Ïì¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ÄÏàòÎ™Ö ÏïàÍ≤πÏπòÍ≤å df1ÏúºÎ°ú.
  df1 = df1[df1['BIAS_DESC'].str.contains('Anti-Asian', na = False)]     ## Anti-Asian
  df1 = df1[(df1['DATA_YEAR'] >= 2019)]      ## 2019, 2020

  # crime type table
  offense_type_tab = pd.crosstab(df1.DATA_YEAR, df1.OFFENSE_NAME)
  # offense_type_tab

  # crime type cleaning
  df1.loc[(df1['OFFENSE_NAME'].str.startswith('Aggravated Assault')), 'OFFENSE_NAME'] = 'Aggravated Assault'
  df1.loc[(df1['OFFENSE_NAME'].str.startswith('Destruction/Damage/Vandalism of Property')), 'OFFENSE_NAME'] = 'Destruction/Damage/Vandalism of Property'
  df1.loc[(df1['OFFENSE_NAME'].str.startswith('Intimidation')), 'OFFENSE_NAME'] = 'Intimidation'
  df1.loc[(df1['OFFENSE_NAME'].str.contains('Drug')), 'OFFENSE_NAME'] = 'Drug Violations'
  df1.loc[(df1['OFFENSE_NAME'].str.contains('Theft')), 'OFFENSE_NAME'] = 'Theft'

  # crime type cleaning (2nd)
  df1.loc[df1['OFFENSE_NAME'] == 'Intimidation', 'OFFENSE_NAME'] = 1
  df1.loc[df1['OFFENSE_NAME'] == 'Counterfeiting/Forgery', 'OFFENSE_NAME'] = 1
  df1.loc[df1['OFFENSE_NAME'] == 'Drug Violations', 'OFFENSE_NAME'] = 1
  df1.loc[df1['OFFENSE_NAME'] == 'Weapon Law Violations', 'OFFENSE_NAME'] = 1

  df1.loc[df1['OFFENSE_NAME'] == 'All Other Larceny', 'OFFENSE_NAME'] = 2
  df1.loc[df1['OFFENSE_NAME'] == 'Theft', 'OFFENSE_NAME'] = 2
  df1.loc[df1['OFFENSE_NAME'] == 'Destruction/Damage/Vandalism of Property', 'OFFENSE_NAME'] = 2

  #Î∞©Ìôî, Í∞ïÎèÑ, Ï£ºÍ±∞Ïπ®ÏûÖÍ∞ïÎèÑ Î™®Îëê 2ÏóêÏÑú 3ÏúºÎ°ú ÏòÆÍπÄ
  df1.loc[df1['OFFENSE_NAME'] == 'Simple Assault', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Aggravated Assault', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Robbery', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Burglary/Breaking & Entering', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Arson', 'OFFENSE_NAME'] = 3

  df1.loc[df1['OFFENSE_NAME'] == 'Rape', 'OFFENSE_NAME'] = 4
  df1.loc[df1['OFFENSE_NAME'] == 'Murder and Nonnegligent Manslaughter', 'OFFENSE_NAME'] = 4

  df1.loc[df1['OFFENSE_NAME'] == 'Not Specified', 'OFFENSE_NAME'] = 5
  df1.loc[df1['OFFENSE_NAME'] == 'Hacking/Computer Invasion', 'OFFENSE_NAME'] = 5

  # crime type table (numeric order)
  offense_type_tab_c = pd.crosstab(df1.DATA_YEAR, df1.OFFENSE_NAME)

  # Line and Bar plot for crime type
  offense_type_line = pd.crosstab(df1.OFFENSE_NAME, columns= df1.DATA_YEAR)
  offense_type_bar = pd.crosstab(df1.OFFENSE_NAME, columns= df1.DATA_YEAR, normalize=True)
  offense_type_line_plt = px.line(offense_type_line, title = "Graph by type of crimes", markers=True, )
  offense_type_line_plt.update_layout(xaxis = dict({"title" : "Crime Type"}), yaxis = dict({"title" : "Counted Cases"}))
  offense_type_bar_plt = px.bar(offense_type_bar, title = " ", barmode = "group")
  offense_type_bar_plt.update_layout(xaxis = dict({"title" : "Crime Type"}), yaxis = dict({"title" : "Counted Cases"}))

  col1, col2 = st.columns(2)

  with col1:
      st.plotly_chart(offense_type_line_plt, use_container_width = True)

  with col2:
      st.plotly_chart(offense_type_bar_plt, use_container_width = True)

  st.info('''
  * ÌòêÏò§ Î≤îÏ£Ñ, ‚ÄòÎßéÏù¥‚ÄôÎßå ÏùºÏñ¥ÎÇú Í≤å ÏïÑÎãàÎã§: Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±ÎèÑ ÎåÄÌè≠ Ï¶ùÍ∞ÄÌñàÏñ¥Ïöî. ÏÇ¥Ïù∏Í≥º Í∞ôÏùÄ Í≥ºÍ≤©ÏÑ± 4 Ï†ïÎèÑÏùò Ï§ëÎ≤îÏ£ÑÎ•º Ï†úÏô∏ÌïòÍ≥†, 2019ÎÖÑ ÎåÄÎπÑ 2020ÎÖÑ ÏïÑÏãúÏïÑÏù∏ÏùÑ ÎåÄÏÉÅÏúºÎ°ú Ìïú Í≥ºÍ≤©ÏÑ± 1~3Ïùò ÌòêÏò§ Î≤îÏ£Ñ ÎπÑÏ§ëÏù¥ ÎÜíÏïÑÏßÑ Í≤É Î≥¥Ïù¥ÏãúÎÇòÏöî?
  * Í≤ΩÎ≤îÏ£Ñ, Ï§ëÎ≤îÏ£Ñ Î™®Îëê Ï¶ùÍ∞Ä: 1~2Î°ú Î∂ÑÎ•òÎêòÎäî Í≤ΩÎ≤îÏ£ÑÎäî Î¨ºÎ°†, Ìè≠ÌñâÍ≥º Í∞ïÎèÑ Îì±Ïùò Ï§ëÎ≤îÏ£ÑÎèÑ ÏïÑÏãúÏïÑÏù∏ÏùÑ ÎåÄÏÉÅÏúºÎ°ú Ï†ÅÏßÄ ÏïäÍ≤å ÌñâÌï¥Ï°åÎÑ§Ïöî.
          ''')

  st.markdown('''
              #
  #
              ''')


  # section2-3 : Î≤îÏ£ÑÏùò Í≥µÍ∞úÏÑ±: ÎùºÏù∏, ÎßâÎåÄ
  st.subheader("ÌòêÏò§ Î≤îÏ£ÑÏùò Í≥µÍ∞úÏÑ±, ÏΩîÎ°úÎÇò19 Ï†ÑÌõÑÎ•º Î≥ºÍπå?")

  st.success('''
  2019ÎÖÑ ~ 2020ÎÖÑ: Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ± Î≥ÄÌôî\nÎ≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ±ÏùÄ Ïû•ÏÜåÏùò Í∞úÎ∞©ÏÑ±Í≥º Í≥µÍ≥µÏÑ±, Ïú†Îèô Ïù∏Íµ¨Î•º Í≥†Î†§Ìï¥ 1~5Ïùò ÏàòÏπòÎ°ú Î∂ÑÎ•òÌñàÏúºÎ©∞, Ïà´ÏûêÍ∞Ä Ïª§ÏßàÏàòÎ°ù Í≥µÍ∞úÏÑ±Ïù¥ ÎÜíÏùåÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§. Í≥µÍ∞úÏÑ±Ïù¥ 1, 2Ïù¥Î©¥ ÌèêÏáÑÏ†ÅÏù∏ Ïû•ÏÜå, Í≥µÍ∞úÏÑ±Ïù¥ 3Ïù¥Î©¥ Í≥µÍ∞Ñ Í∞úÎ∞©ÏÑ±ÏùÄ ÎÜíÏúºÎÇò Ïú†ÎèôÏù∏Íµ¨Îäî Ï†ÅÏùÄ Ïû•ÏÜå, Í≥µÍ∞úÏÑ±Ïù¥ 4,5Ïù¥Î©¥ Ïú†Îèô Ïù∏Íµ¨ÏôÄ Í≥µÍ≥µÏÑ±Ïù¥ Î™®Îëê ÎÜíÏùÄ Ïû•ÏÜåÏûÖÎãàÎã§. 

  *6ÏùÄ Í≥µÍ∞úÏÑ±ÏùÑ ÏûÑÏùòÎ°ú Ï∏°Ï†ïÌïòÍ∏∞ Ïñ¥Î†§Ïö¥ Í∏∞ÌÉÄ Î≤îÏ£Ñ Ïû•ÏÜåÏûÖÎãàÎã§.

  1 = Ïßë(Residence/Home), ÏàôÎ∞ïÏóÖÏÜå(Hotel/Motel/Etc.)\n
  2 = Ï†ÑÎ¨∏ÏÉÅÏ†ê(Specialty store), Ï£ºÎ•ò ÌåêÎß§Ï†ê(Liquor Store), Ï∞® ÎîúÎü¨ÏÉµ(Auto Dealership New/Used)\n
  3 = Í≥µÏû• Î∂ÄÏßÄ(Industrial Site), Îì§Ìåê¬∑Ïà≤(Field/Woods), Í∞ïÍ∞Ä¬∑Î∞îÎã∑Í∞Ä(Lake/Waterway/Beach), Ï£ºÏ∞®Ïû•¬∑Ï∞®Í≥†(Parking/Drop Lot/Garage), Ï£ºÏú†ÏÜå¬∑ÏÑúÎπÑÏä§ÏÑºÌÑ∞(Service/Gas Station)\n
  4 = Ïà†Ïßë¬∑ÎÇòÏù¥Ìä∏ÌÅ¥ÎüΩ(Bar/Nightclub), ÏãùÎãπ(Restaurant), Í≥µÏõê¬∑ÎÜÄÏù¥ÌÑ∞(Park/Playground), ÎèÑÎ°ú¬∑Î≥¥ÎèÑ(Highway/Road/Alley/Street/Sidewalk), Ìú¥Í≤åÏÜå(rest area), convenience store(Ìé∏ÏùòÏ†ê), Î∞±ÌôîÏ†ê¬∑Ìï†Ïù∏ÌåêÎß§Ï†ê(Department/Discount Store), ÏáºÌïëÎ™∞(Shopping Mall), ÏãùÎ£åÌíàÏ†ê¬∑ÏäàÌçºÎßàÏºì(Grocery/Supermarket), ÍµêÌÜµ ÏãúÏÑ§(Air/Bus/Train Terminal), ÏÉÅÏóÖÏö© Í±¥Î¨º(Commercial/Office Building)\n
  5 = Ï¥à¬∑Ï§ëÎì±¬∑ÎåÄÌïôÍµê(School-College/Elementary/Secondary), Ï£ºÎØºÏûêÏπòÏÑºÌÑ∞(Community Center), ÌôàÎ¶¨Ïä§ ÏâºÌÑ∞(Shelter-Mission/Homeless), ÏùÄÌñâ(Bank/Savings and Loan), Ï¢ÖÍµê ÏãúÏÑ§(Church/Synagogue/Temple/Mosque), Ï†ïÎ∂Ä¬∑Í≥µÍ≥µÍ∏∞Í¥Ä Í±¥Î¨º(Church/Synagogue/Temple/Mosque), ÏùòÎ£åÍ∏∞Í¥Ä(Drug Store/Doctor's Office/Hospital)\n
  6 = ÏïåÎ†§ÏßÄÏßÄ ÏïäÏùå(Other/Unknown), Ïò®ÎùºÏù∏ Í≥µÍ∞Ñ(Cyber space)
             ''')

  # crime place cleaning
  df1.loc[df1['LOCATION_NAME'] == 'Residence/Home', 'LOCATION_NAME'] = 1
  df1.loc[df1['LOCATION_NAME'] == 'Hotel/Motel/Etc.', 'LOCATION_NAME'] = 1

  df1.loc[df1['LOCATION_NAME'] == 'Auto Dealership New/Used', 'LOCATION_NAME'] = 2
  df1.loc[df1['LOCATION_NAME'] == 'Specialty Store', 'LOCATION_NAME'] = 2
  df1.loc[df1['LOCATION_NAME'] == 'Liquor Store', 'LOCATION_NAME'] = 2

  df1.loc[df1['LOCATION_NAME'] == 'Field/Woods', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Lake/Waterway/Beach', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Parking/Drop Lot/Garage', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Service/Gas Station', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Industrial Site', 'LOCATION_NAME'] = 3

  df1.loc[df1['LOCATION_NAME'] == 'Convenience Store', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Department/Discount Store', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Shopping Mall', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Grocery/Supermarket', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Air/Bus/Train Terminal', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Commercial/Office Building', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Park/Playground', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Highway/Road/Alley/Street/Sidewalk', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Rest Area', 'LOCATION_NAME'] = 4.
  df1.loc[df1['LOCATION_NAME'] == 'Bar/Nightclub', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Restaurant', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Highway/Road/Alley/Street/Sidewalk;Residence/Home', 'LOCATION_NAME'] = 4


  
  df1.loc[df1['LOCATION_NAME'] == 'School-College/University', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'School-Elementary/Secondary', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'School/College', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Community Center', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Shelter-Mission/Homeless', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Bank/Savings and Loan', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Church/Synagogue/Temple/Mosque', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Government/Public Building', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == "Drug Store/Doctor's Office/Hospital", 'LOCATION_NAME'] = 5


  df1.loc[df1['LOCATION_NAME'] == 'Cyberspace', 'LOCATION_NAME'] = 6
  df1.loc[df1['LOCATION_NAME'] == 'Other/Unknown', 'LOCATION_NAME'] = 6

  # Line and Bar plot for publicity of place
  offense_place_tab_c = pd.crosstab(df1.LOCATION_NAME, df1.DATA_YEAR)
  offense_place_line = pd.crosstab(df1.LOCATION_NAME, columns = df1.DATA_YEAR)
  offense_place_bar = pd.crosstab(df1.LOCATION_NAME, columns = df1.DATA_YEAR)

  offense_place_line_plt = px.line(offense_place_line, title = "Graph by type of places")
  offense_place_bar_plt = px.bar(offense_place_bar, title = " ", barmode = "group")

  offense_place_line_plt.update_layout(xaxis = dict({"title" : "Crime Location"}), yaxis = dict({"title" : "Counted Cases"}))
  offense_place_bar_plt.update_layout(xaxis = dict({"title" : "Crime Location"}), yaxis = dict({"title" : "Counted Cases"}))

  col1, col2 = st.columns(2)

  with col1:
      st.plotly_chart(offense_place_line_plt, use_container_width = True)
  with col2:
      st.plotly_chart(offense_place_bar_plt, use_container_width = True)

  st.info('''
  * ÏùºÏÉÅÏ†Å Í≥µÍ∞ÑÏóê Ïä§Î©∞Îì† ÌòêÏò§ Î≤îÏ£Ñ: Ïú†Îèô Ïù∏Íµ¨Í∞Ä ÎßéÍ≥† Í∞úÎ∞©ÏÑ±Ïù¥ ÎÜíÏùÄ Í≥µÍ∞úÏÑ± 4Ïùò Ïû•ÏÜåÏóêÏÑú Î∞úÏÉùÌïú ÌòêÏò§ Î≤îÏ£Ñ ÎπàÎèÑÏàòÍ∞Ä Ï†ÑÎÖÑÎèÑ ÎåÄÎπÑ 2020ÎÖÑ Îëê Î∞∞ Í∞ÄÎüâ Ï¶ùÍ∞ÄÌñàÏñ¥Ïöî. Í≥µÍ∞úÏÑ± 1~3Ïùò Ïû•ÏÜåÏóêÏÑú Î∞úÏÉùÌïú Î≤îÏ£ÑÎèÑ Ï¶ùÍ∞ÄÌñàÏßÄÎßå, Í≥µÍ∞úÏÑ± 4Í∞Ä Ïú†ÎèÖ Ï¶ùÍ∞ÄÌñàÎÑ§Ïöî. Î≤îÏ£Ñ Ïû•ÏÜåÏùò Ï¶ùÍ∞ÄÌïú Í≥µÍ∞úÏÑ±ÏùÄ ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä ÎçîÏö± Í≥µÍ≥µÏó∞ÌïòÍ≤å Î∞úÏÉùÌïòÍ≥† ÏûàÏùåÏùÑ Î≥¥Ïó¨Ï§òÏöî.
          ''')


  st.markdown("""
  ##### ‚úãÏû†Íπê! Ïó¨Í∏∞ÍπåÏßÄ Ï†ïÎ¶¨ ‚úã
  * ÎØ∏Íµ≠ Ï†ÑÏó≠ Í∏∞Ï§ÄÏúºÎ°ú Î¥§ÏùÑ Îïå, ÏΩîÎ°úÎÇò19Í∞Ä Î∞úÏÉùÌïú 2020ÎÖÑ Ï¥àÎ•º Í∏∞Ï†êÏúºÎ°ú ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÍ∞Ä Í∏âÏ¶ùÌñàÏñ¥Ïöî. Í∞ïÎèÑ, Ìè≠Ìñâ Îì± Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±ÎèÑ Ï¶ùÍ∞ÄÌñàÍ≥†, Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ≥µÏÑ±Í≥º Í∞úÎ∞©ÏÑ±, Ïú†ÎèôÏù∏Íµ¨Î•º Ï≤ôÎèÑÎ°ú Îß§Í∏¥ Í≥µÍ∞úÏÑ±ÎèÑ Ìï®Íªò Ï¶ùÍ∞ÄÌñàÍ≥†Ïöî. 
  * ÏöîÏª®ÎåÄ ÏΩîÎ°úÎÇò19Ïùò Î∞úÏÉùÍ≥º ÎØ∏Íµ≠ ÎÇ¥ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Ïã¨Í∞ÅÏÑ±ÏùÄ, ÏùºÏ¢ÖÏùò ÏÉÅÍ¥ÄÍ¥ÄÍ≥ÑÎ•º ÏßÄÎãàÍ≥† ÏûàÏùåÏùÑ Ï∂îÎ°†Ìï† Ïàò ÏûàÏñ¥Ïöî.
  """)

elif add_radio == "üîçÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, ÏßÄÏó≠ÏúºÎ°ú Ï¢ÅÌòÄ Î≥¥Ïûê!":
    # section 3: Ï£ºÎ≥Ñ ÎπÑÍµê

    st.markdown('''
    ## üîçÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ, ÏßÄÏó≠ÏúºÎ°ú Ï¢ÅÌòÄ Î≥¥Ïûê!
                ''')
    st.subheader("ÏΩîÎ°úÎÇò19 ÌîºÌï¥Í∞Ä Ïã¨Ìïú Ï£ºÏùºÏàòÎ°ù ÌòêÏò§ Î≤îÏ£ÑÎèÑ ÎßéÏïòÏùÑÍπå?")
    st.success("""
    üìå ÎØ∏Íµ≠ Ï£ºÎ≥Ñ ÏïÑÏãúÏïÑÏù∏ Ïù∏Íµ¨\n
    üìå 2020ÎÖÑ Í∏∞Ï§Ä, ÎØ∏Íµ≠ Ï£ºÎ≥Ñ Ïù∏Íµ¨ Ï≤ú Î™ÖÎãπ ÏΩîÎ°úÎÇò19Î°ú Ïù∏Ìïú ÏÇ¨ÎßùÏûê Ïàò\n
    üìå 2019ÎÖÑÍ≥º 2020ÎÖÑ, ÎØ∏Íµ≠ Ï£ºÎ≥Ñ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í±¥Ïàò\n
    ÏÑ∏ Í∞ÄÏßÄÎ•º Í∞ÅÍ∞Å ÏãúÍ∞ÅÌôîÌïú ÏßÄÎèÑÎì§ ÏÇ¥Ìé¥Î≥¥ÏïÑÏöî! 
    """)



    # section 3-1: ÏïÑÏãúÏïÑÏù∏ Ïù∏Íµ¨

    image = Image.open('population_map.png')
    st.image(image, caption = "Population of Asian in US")

    st.markdown('''
    #
                ''')



    # section 3-2: ÏÇ¨ÎßùÏûêÏàò

    #ÌååÏùº ÏûÑÌè¨Ìä∏ 
    covid_state = pd.read_csv("us_county_covid_2020.csv") #2020ÎÖÑ 12Ïõî 31Ïùº Í∏∞Ï§Ä, ÎØ∏Íµ≠ Í∞Å Ï£º countyÎ≥Ñ ÎàÑÏ†Å ÌôïÏßÑ ÏàòÎ•º Îã¥ÏùÄ ÌååÏùº.

    #Ï£ºÎ≥Ñ Ïù∏Íµ¨ 10ÎßåÎ™Ö Îãπ ÏΩîÎ°úÎÇò19 ÌôïÏßÑÏûê Ïàò Ìëú Í∑∏Î¶¨Í∏∞
    covid_state_df = pd.DataFrame(covid_state)

    @st.cache #Ï∫êÏãú ÏÇ¨Ïö©ÌïòÎèÑÎ°ù ÏÑ§Ï†ï
    #Ï£ºÎ≥Ñ ÎàÑÏ†Å ÏÇ¨Îßù Í±¥Ïàò Ï∂îÏ∂ú Ìï®Ïàò
    def state_deaths(state_name):
        state = covid_state_df.loc[covid_state_df['state'] == state_name]
        return state['deaths'].sum()

    state_name_list = list(covid_state_df['state'].unique())

    deaths_list = []
    for item in state_name_list:
        deaths_list.append(int(state_deaths(item)))

    #deaths_list

    state_death = {'State':state_name_list, 'Deaths':deaths_list}
    state_death_df = pd.DataFrame(state_death)

    #10Îßå Î™ÖÎãπ: (Ï†ÑÏ≤¥ Í±¥Ïàò / 2020 Í∏∞Ï§Ä Ìï¥Îãπ Ï£º Ïù∏Íµ¨Ïàò) * 100,000 - Ìï¥Îãπ Ï£º Ïù∏Íµ¨ÏàòÎäî us census.gov ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Í∞ÄÏ†∏Ïò® ÌååÏùº, 2020 7Ïõî Í∏∞Ï§Ä
    us_population = pd.read_csv("us_population_2020.csv")
    us_population['2020'] = us_population['2020'].apply(lambda x: int(x.replace(',', '')))
    us_death_population = pd.merge(state_death_df, us_population)

    #1Ï≤ú Î™ÖÎãπ ÏÇ¨ÎßùÏûê Ïàò : (Ï†ÑÏ≤¥ Í±¥Ïàò / 2020 Í∏∞Ï§Ä Ìï¥Îãπ Ï£º Ïù∏Íµ¨Ïàò) * 1000
    us_death_population['deaths_per_1k'] = us_death_population.apply(lambda x: ((x['Deaths'] / x['2020']) * 1000), axis=1)
    us_death_population_final = us_death_population[['State', 'deaths_per_1k']]

    from urllib.request import urlopen
    import json
    with urlopen('https://raw.githubusercontent.com/ChoiDayeun/datajournalism_streamlit/main/us-states_json_edit.json') as response:
        states = json.load(response)

    #ÏßÄÎèÑ Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨ÏôÄÏÑú ÏãúÍ∞ÅÌôî.
    fig_death_population = px.choropleth(us_death_population_final, geojson= states, locations='State', 
                        color = 'deaths_per_1k',
                        color_continuous_scale="Reds",
                        range_color=(0, us_death_population_final.deaths_per_1k.max()),
                        featureidkey='properties.State',
                        scope="usa",
                        labels={'deaths_per_1k':'deaths per 1k'},
                        title = 'US COVID-19 Deaths per 1k by States'
                        )
    fig_death_population.update_layout(margin={"r":0,"t":60,"l":0,"b":0})
    #fig_death_population.show()

    st.plotly_chart(fig_death_population, use_container_width = True)




    # section 3-3 : 2019/2020 Asian hate crime
    #Ï£ºÎ≥Ñ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§Î≤îÏ£Ñ Í±¥Ïàò Ìëú Í∑∏Î¶¨Í∏∞: 2019, 2020
    fbi_2019 = fbi.loc[fbi['DATA_YEAR'] == 2019]
    fbi_2019 = fbi_2019[fbi_2019['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    fbi_state_2019 = fbi_2019[['STATE_NAME']]

    #Í∞Å Ï£ºÎ≥Ñ Î≤îÏ£Ñ Ï¥ù Í±¥Ïàò ÏÑ∏Îäî Ìï®Ïàò
    @st.cache #Ï∫êÏãú ÏÇ¨Ïö©ÌïòÎèÑÎ°ù ÏÑ§Ï†ï
    def state_crimes(state_name):
        state = fbi_state_2019.loc[fbi_state_2019['STATE_NAME'] == state_name]
        return len(state)

    #state_crimes('New York')

    crime_list_2019 = []
    for item in state_name_list:
        #print(item)
        crime_list_2019.append(int(state_crimes(item)))

    state_crime_2019 = {'State':state_name_list, 'Crimes':crime_list_2019}
    state_crime_df_2019 = pd.DataFrame(state_crime_2019)
    #state_crime_df_2019

    ###############2020ÎÖÑ##################
    fbi_2020 = fbi.loc[fbi['DATA_YEAR'] == 2020]
    fbi_2020 = fbi_2020[fbi_2020['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    fbi_state_2020 = fbi_2020[['STATE_NAME']]

    #Í∞Å Ï£ºÎ≥Ñ Î≤îÏ£Ñ Ï¥ù Í±¥Ïàò ÏÑ∏Îäî Ìï®Ïàò
    @st.cache #Ï∫êÏãú ÏÇ¨Ïö©ÌïòÎèÑÎ°ù ÏÑ§Ï†ï
    def state_crimes(state_name):
        state = fbi_state_2020.loc[fbi_state_2020['STATE_NAME'] == state_name]
        return len(state)

    #state_crimes('New York')

    crime_list_2020 = []
    for item in state_name_list:
        #print(item)
        crime_list_2020.append(int(state_crimes(item)))

    state_crime_2020 = {'State':state_name_list, 'Crimes':crime_list_2020}
    state_crime_df_2020 = pd.DataFrame(state_crime_2020)
    #state_crime_df_2019

    ######Ìëú######

    fig_crime_2019 = px.choropleth(state_crime_df_2019, geojson= states, locations='State', 
                        color = 'Crimes',
                        color_continuous_scale="Blues",
                        range_color=(0, state_crime_df_2020.Crimes.max()),
                        featureidkey='properties.State',
                        scope="usa",
                        labels={'case':'Crimes'},
                        title = 'Asian Hate Crime Cases per State 2019', 
                        )
    fig_crime_2019.update_layout(margin={"r":0,"t":60,"l":0,"b":0})
    #fig_crime_2019.show()


    fig_crime_2020 = px.choropleth(state_crime_df_2020, geojson= states, locations='State', 
                        color = 'Crimes',
                        color_continuous_scale="Blues",
                        range_color=(0, state_crime_df_2020.Crimes.max()),
                        featureidkey='properties.State',
                        scope="usa",
                        labels={'case':'Crimes'},
                        title = 'Asian Hate Crime Cases per State 2020', 
                        )
    fig_crime_2020.update_layout(margin={"r":0,"t":60,"l":0,"b":0})


    st.markdown('''
    #
                ''')
    select_yr = st.selectbox('ÌôïÏù∏Ìï† Ìï¥Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî', ['2019', '2020'])
    if select_yr == '2019':
        st.plotly_chart(fig_crime_2019)
    elif select_yr == '2020':
        st.plotly_chart(fig_crime_2020)

    st.info('''
    * ÏΩîÎ°úÎÇò19 ÌîºÌï¥ Ïã¨ÌñàÎçò ÏãúÍ∏∞, ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÎèÑ ÎßéÏïòÎã§: Ïù∏Íµ¨ Ï≤ú Î™ÖÎãπ ÏΩîÎ°úÎÇò19Î°ú Ïù∏Ìïú ÏÇ¨ÎßùÏûê ÏàòÏôÄ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Î∞úÏÉù Í±¥ÏàòÎ•º Ï£ºÎ≥ÑÎ°ú Í∑∏Î¶∞ ÏßÄÎèÑÎûë, ÏïÑÏãúÏïÑÏù∏ Ïù∏Íµ¨ Î∂ÑÌè¨ÎèÑÎ•º Î≥¥Îãà ÏÇ¨ÎßùÏûêÍ∞Ä ÎßéÏùÄ Ï£ºÏóêÏÑú ÌòêÏò§ Î≤îÏ£Ñ ÏàòÎèÑ ÎßéÏù¥ Î∞úÏÉùÌïòÎäî Í≤ΩÌñ•Ïù¥ Î≥¥Ïù¥ÎÑ§Ïöî.
    * ÏúÑ ÌëúÏóêÏÑú Î≥¥Ïù¥ÎìØÏù¥ ÎØ∏Íµ≠ ÎÇ¥ Ï£ºÎ≥ÑÎ°ú ÏïÑÏãúÏïÑÏù∏ Ïù∏Íµ¨ Î∂ÑÌè¨Ïùò Ï∞®Ïù¥Í∞Ä ÌÅ¨Îã§ Î≥¥Îãà, ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Î∞úÏÉù Í±¥ÏàòÍ∞Ä ÎßéÏùÄ Ï£ºÎì§Ïù¥ Ïù∏Íµ¨ Ï≤ú Î™ÖÎãπ ÏΩîÎ°úÎÇò19Î°ú Ïù∏Ìïú ÏÇ¨ÎßùÏûê ÏàòÍ∞Ä ÎßéÏùÄ Ï£ºÎì§Í≥º ÏßÅÏ†ëÏ†ÅÏúºÎ°ú ÏùºÏπòÌïòÏßÄ ÏïäÎäî Í≤ΩÏö∞ÎèÑ ÏûàÏñ¥Ïöî.
    ''')
    
    st.markdown('''
              #
  #
              ''')

    
    st.subheader("ÏΩîÎ°úÎÇò19 ÌîºÌï¥ Ï†ïÎèÑÏôÄ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Ïã¨Í∞ÅÏÑ± Í∞ÑÏóê Í¥ÄÍ≥ÑÍ∞Ä ÏûàÏùÑÍπå?")
    st.success('''
   2020ÎÖÑÏóê ÎØ∏Íµ≠ ÎÇ¥ ÏΩîÎ°úÎÇò19Î°ú Ïù∏Ìï¥ Ïù∏Íµ¨ Ï≤ú Î™ÖÎãπ ÏÇ¨ÎßùÏûê ÏàúÏúºÎ°ú Ï†ïÎ†¨Ìïú Í≤∞Í≥ºÎäî Îã§ÏùåÍ≥º Í∞ôÏïÑÏöîüìá
   * Í∞ÄÏû• ÏÇ¨ÎßùÏûêÍ∞Ä ÎßéÏïòÎçò ÏÉÅÏúÑ 10Í∞ú Ï£ºÎäîüò¢\n: New Jersey, New York, Massachusetts, South Dakota, North Dakota, Connecticut, Rhode Island, Mississippi, Louisiana, Illinois
   * ÎπÑÍµêÏ†Å ÏÇ¨ÎßùÏûêÍ∞Ä Ï†ÅÏóàÎçò ÌïòÏúÑ 10Í∞ú Ï£ºÎäîü•≤\n: Hawaii, Vermont, Maine, Alaska, Oregon, Utah, Washington, Puerto Rico, New Hampshire, Virginia
   ''')
    st.markdown(
              #
  #
              )

    ####Ï£ºÎ≥Ñ Ï†ïÎ¶¨ Îã§Ïãú: 10Í∞ú###
    #1000Î™ÖÎãπ ÏÇ¨ÎßùÏûêÏàòÎ≥ÑÎ°ú Ï†ïÎ†¨: ÏÉÅÏúÑ 10Í∞ú, ÌïòÏúÑ 10Í∞ú Ï£º Ï∂îÏ∂ú
    #ÏÉÅÏúÑ 10Í∞ú, ÌïòÏúÑ 10Í∞ú
    death_top10_df = us_death_population_final.sort_values('deaths_per_1k', ascending = False)[:10]
    death_bottom10_df = us_death_population_final.sort_values('deaths_per_1k')[:10]

    #Ìï¥Îãπ Ï£º Ïù¥Î¶ÑÎì§ Ï∂îÏ∂ú
    death_top10_names = []
    death_bottom10_names = []
    for item in death_top10_df['State']:
        death_top10_names.append(item)

    for item in death_bottom10_df['State']:
        death_bottom10_names.append(item)


    #################ÏÇ¨ÎßùÏûêÏàò Í∏∞Ï§Ä ##################

    df_new2 = pd.DataFrame(fbi, columns=['DATA_YEAR', 'STATE_NAME', 'OFFENSE_NAME', 'BIAS_DESC', 'LOCATION_NAME'])
    df_new2 = df_new2[(df_new2['DATA_YEAR'] >= 2019)]

    df_new2.loc[(df_new2['OFFENSE_NAME'].str.startswith('Aggravated Assault')), 'OFFENSE_NAME'] = 'Aggravated Assault'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.startswith('Murder and Nonnegligent Manslaughter')), 'OFFENSE_NAME'] = 'Murder and Nonnegligent Manslaughter'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Destruction/Damage/Vandalism of Property')), 'OFFENSE_NAME'] = 'Destruction/Damage/Vandalism of Property'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Intimidation')), 'OFFENSE_NAME'] = 'Intimidation'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Drug')), 'OFFENSE_NAME'] = 'Drug Violations'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Theft')), 'OFFENSE_NAME'] = 'Theft'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Robbery')), 'OFFENSE_NAME'] = 'Robbery'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Burglary')), 'OFFENSE_NAME'] = 'Burglary'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Fraud')), 'OFFENSE_NAME'] = 'Fraud'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Rape')), 'OFFENSE_NAME'] = 'Rape'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Prostitution')), 'OFFENSE_NAME'] = 'Prostitution'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Arson')), 'OFFENSE_NAME'] = 'Arson'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.startswith('Kidnapping')), 'OFFENSE_NAME'] = 'Kidnapping'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Extortion')), 'OFFENSE_NAME'] = 'Extortion'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Shoplifting')), 'OFFENSE_NAME'] = 'Shoplifting'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Purse-snatching')), 'OFFENSE_NAME'] = 'Shoplifting'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Pocket-picking')), 'OFFENSE_NAME'] = 'Shoplifting' #ÏïΩÍ∞Ñ Ï¢ÄÎèÑÎëë ÎäêÎÇåÏù¥Î©¥ Îã§ shoplifting 
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Fondling')), 'OFFENSE_NAME'] = 'Fondling'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Simple Assault')), 'OFFENSE_NAME'] = 'Simple Assault'


    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('All Other Larceny')), 'OFFENSE_NAME'] = 'All Other Larceny' #Îã§ Ï†ïÎ¶¨ÌïòÍ≥†ÎèÑ ÎÇ®ÏúºÎ©¥ Í∏∞ÌÉÄÎ°ú ÎπºÍ∏∞.

    # crime type cleaning (2nd)
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Intimidation', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Counterfeiting/Forgery', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Drug Violations', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Weapon Law Violations', 'OFFENSE_NAME'] = 1 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Embezzlement', 'OFFENSE_NAME'] = 1 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Sodomy', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Extortion', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Fondling', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Pornography/Obscene Material', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Shoplifting', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Impersonation', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Fraud', 'OFFENSE_NAME'] = 1 #ÏÇ¨Í∏∞ÍπåÏßÄ
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'False Pretenses/Swindle/Confidence Game', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Stolen Property Offenses', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Animal Cruelty', 'OFFENSE_NAME'] = 1

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'All Other Larceny', 'OFFENSE_NAME'] = 2
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Theft', 'OFFENSE_NAME'] = 2 #Ïó¨Í∏∞ÏÑúÎ∂ÄÌÑ∞Îäî Ï†àÎèÑ Îì±Îì±
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Destruction/Damage/Vandalism of Property', 'OFFENSE_NAME'] = 2
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Prostitution', 'OFFENSE_NAME'] = 2 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Human Trafficking, Commercial Sex Acts', 'OFFENSE_NAME'] = 2

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Arson', 'OFFENSE_NAME'] = 3 #Î∞©ÌôîÎäî 3ÏúºÎ°ú ÎπºÎäî Í≤ÉÏùÄ Ïñ¥Îñ®ÏßÄ? 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Robbery', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Burglary', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Simple Assault', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Aggravated Assault', 'OFFENSE_NAME'] = 3 #Í∞ÄÏ§ë Ìè≠Ìñâ
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Sexual Assault With An Object', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Negligent Manslaughter', 'OFFENSE_NAME'] = 3

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Kidnapping', 'OFFENSE_NAME'] = 4 #Ïú†Í¥¥ 3? 4?
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Rape', 'OFFENSE_NAME'] = 4
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Murder and Nonnegligent Manslaughter', 'OFFENSE_NAME'] = 4

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Not Specified', 'OFFENSE_NAME'] = 5
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Hacking/Computer Invasion', 'OFFENSE_NAME'] = 5 #1Î°ú Î≥¥ÎÇ¥Îäî Í≤ÉÏùÄ Ïñ¥Îñ®ÏßÄ? 


    # crime place cleaning 1st

    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Highway/Road/Alley/Street/Sidewalk')), 'LOCATION_NAME'] = 'Highway/Road/Alley/Street/Sidewalk'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Store')), 'LOCATION_NAME'] = 'Store'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Facility')), 'LOCATION_NAME'] = 'Facility'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('School-Elementary/Secondary')), 'LOCATION_NAME'] = 'School-Elementary/Secondary'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Auto Dealership New/Used')), 'LOCATION_NAME'] = 'Auto Dealership New/Used'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.startswith('Hotel/Motel/Etc')), 'LOCATION_NAME'] = 'Hotel/Motel/Etc'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Amusement Park')), 'LOCATION_NAME'] = 'Amusement Park' 
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Commercial/Office Building')), 'LOCATION_NAME'] = 'Commercial/Office Building'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('ATM Separate from Bank')), 'LOCATION_NAME'] = 'ATM Separate from Bank'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.startswith('Grocery/Supermarket')), 'LOCATION_NAME'] = 'Grocery/Supermarket'  

    df_new2.loc[(df_new2['LOCATION_NAME'].str.startswith('Other/Unknown')), 'LOCATION_NAME'] = 'Other/Unknown' #Í∏∞ÌÉÄ 

    # crime place cleaning 2nd
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Residence/Home', 'LOCATION_NAME'] = 1
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Hotel/Motel/Etc', 'LOCATION_NAME'] = 1


    df_new2.loc[df_new2['LOCATION_NAME'] == 'ATM Separate from Bank', 'LOCATION_NAME'] = 2 
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Auto Dealership New/Used', 'LOCATION_NAME'] = 2
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Abandoned/Condemned Structure', 'LOCATION_NAME'] = 2
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Military Installation', 'LOCATION_NAME'] = 2 #ÏñòÎèÑ 3ÏúºÎ°ú ÎπºÎäî Í≤ÉÏùÄ Ïñ¥Îñ®ÏßÄ?


    df_new2.loc[df_new2['LOCATION_NAME'] == 'Construction Site', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Industrial Site', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Field/Woods', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Camp/Campground', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Arena/Stadium/Fairgrounds/Coliseum', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Tribal Lands', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Service/Gas Station', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Lake/Waterway/Beach', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Parking/Drop Lot/Garage', 'LOCATION_NAME'] = 3

    df_new2.loc[df_new2['LOCATION_NAME'] == 'Store', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Facility', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Shopping Mall', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Grocery/Supermarket', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Air/Bus/Train Terminal', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Dock/Wharf/Freight/Modal Terminal', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Commercial/Office Building', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Bar/Nightclub', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Restaurant', 'LOCATION_NAME'] = 4

    df_new2.loc[df_new2['LOCATION_NAME'] == 'School-College/University', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'School-Elementary/Secondary', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'School/College', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Community Center', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Shelter-Mission/Homeless', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Bank/Savings and Loan', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Church/Synagogue/Temple/Mosque', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Government/Public Building', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == "Drug Store/Doctor's Office/Hospital", 'LOCATION_NAME'] = 5 


    df_new2.loc[df_new2['LOCATION_NAME'] == 'Amusement Park', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Park/Playground', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Highway/Road/Alley/Street/Sidewalk', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Rest Area', 'LOCATION_NAME'] = 4


    df_new2.loc[df_new2['LOCATION_NAME'] == 'Cyberspace', 'LOCATION_NAME'] = 6
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Other/Unknown', 'LOCATION_NAME'] = 6


    #death_top10_names,  death_bottom10_namesÏóê ÏûàÎäî Ï£ºÎì§Ïùò Í∞íÏùÑ Î∞îÍæº ÌõÑ, dfÏóê Ìï¥Îãπ Ïª¨ÎüºÎì§Îßå ÎÇ®ÍπÄ: ÏÉÅÏúÑ 10Í∞ú : TOP_10_COVID_deathS, BOTTOM_10_COVID_deathS
    for item in death_top10_names:
        df_new2.loc[df_new2['STATE_NAME'] == item, 'STATE_NAME'] = 'TOP_10_COVID_DEATHS'
    for item in death_bottom10_names:
        df_new2.loc[df_new2['STATE_NAME'] == item, 'STATE_NAME'] = 'BOTTOM_10_COVID_DEATHS'
    df_deaths_state = df_new2.loc[(df_new2['STATE_NAME'] == 'TOP_10_COVID_DEATHS') | (df_new2['STATE_NAME'] == 'BOTTOM_10_COVID_DEATHS')]


    ##ÏïÑÏãúÏïÑÏù∏ ÎåÄÏÉÅ ÌòêÏò§Î≤îÏ£ÑÎßå, ÏÇ¨ÎßùÏûêÏàò Í∏∞Ï§ÄÏúºÎ°ú Ï∂îÏ∂ú
    df_state_asian = df_deaths_state[df_deaths_state['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    df_state_asian = df_deaths_state[df_deaths_state['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    
    #ÏÇ¨ÎßùÏûê Ïàò ÏÉÅÏúÑ 10Í∞ú/ÌïòÏúÑ 10Í∞ú Ï£º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ
    top10_asian_df = df_state_asian[df_state_asian['STATE_NAME'] == 'TOP_10_COVID_DEATHS']
    bottom10_asian_df = df_state_asian[df_state_asian['STATE_NAME'] == 'BOTTOM_10_COVID_DEATHS']
    
    #ÏÉÅÏúÑ 10Í∞ú Ï£º Ï¢ÖÎ•òÎ≥Ñ Ï†ïÎ¶¨
    pd_top10 = pd.crosstab(top10_asian_df['OFFENSE_NAME'], top10_asian_df['DATA_YEAR'])
    pd_top10_loc = pd.crosstab(top10_asian_df['LOCATION_NAME'],top10_asian_df['DATA_YEAR'])
    
    #ÌïòÏúÑ 10Í∞ú Ï£º Ï¢ÖÎ•òÎ≥Ñ Ï†ïÎ¶¨
    pd_bottom10 = pd.crosstab(bottom10_asian_df['OFFENSE_NAME'], bottom10_asian_df['DATA_YEAR'])
    pd_bottom10_loc = pd.crosstab(bottom10_asian_df['LOCATION_NAME'], bottom10_asian_df['DATA_YEAR'])
    
    
    
    #ÏÇ¨ÎßùÏûêÏàò Í∞ÄÏû• ÎßéÏùÄ ÏÉÅÏúÑ 10Í∞ú Ï£º Í∏∞Ï§Ä
    
    #Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±
    raw_data = {'year': [2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2020],
                'offense_name': list(pd_top10.index) * 2,
                'offense_number': list(pd_top10[2019]) + list(pd_top10[2020])}

    offense_name = pd.DataFrame(raw_data)


    fig_off_asian = px.scatter(offense_name, x="offense_number", y="offense_name",  color="year", color_continuous_scale='Bluered_r',  title = 'Î≤îÏ£Ñ ÏñëÏÉÅÏùò Í≥ºÍ≤©ÏÑ±-ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûê ÏÉÅÏúÑ 10Í∞ú Ï£º Í∏∞Ï§Ä')
    # iterate on each region
    for i in offense_name["offense_name"].unique():
        # filter by region
        df_sub = offense_name[offense_name["offense_name"] == i]

        fig_off_asian.add_shape(
            type="line",
            layer="below",
            # connect the two markers
            y0=df_sub.offense_name.values[0], x0=df_sub.offense_number.values[0],
            y1=df_sub.offense_name.values[1], x1=df_sub.offense_number.values[1], 
        )
    

    #Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ±
    raw_data2 = {'year': [2019, 2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2020, 2020],
                'location_name': list(pd_top10_loc.index) * 2,
                'location_number': list(pd_top10_loc[2019]) + list(pd_top10_loc[2020])}

    location_names = pd.DataFrame(raw_data2)

    fig_loc_asian = px.scatter(location_names, x="location_number", y="location_name", color="year", color_continuous_scale='Bluered_r', title = 'Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ±-ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûê ÏÉÅÏúÑ 10Í∞ú Ï£º Í∏∞Ï§Ä')
    # iterate on each region
    for i in location_names["location_name"].unique():
        df_sub = location_names[location_names["location_name"] == i]

        fig_loc_asian.add_shape(
            type="line",
            layer="below",
            # connect the two markers
            y0=df_sub.location_name.values[0], x0=df_sub.location_number.values[0],
            y1=df_sub.location_name.values[1], x1=df_sub.location_number.values[1], 
        )
    
    
   #ÏÇ¨ÎßùÏûê Ïàò ÌïòÏúÑ 10Í∞ú Ï£ºÏùò Í≤ΩÏö∞
    raw_data_3 = {'year': [2019, 2019, 2019, 2020, 2020, 2020],
                'offense_name': list(pd_bottom10.index) * 2,
                'offense_number': list(pd_bottom10[2019]) + list(pd_bottom10[2020])}

    offense_name3 = pd.DataFrame(raw_data_3)

    fig_off_asian_bottom = px.scatter(offense_name3, x="offense_number", y="offense_name",    color="year", color_continuous_scale='Bluered_r',  title = 'Î≤îÏ£Ñ ÏñëÏÉÅÏùò Í≥ºÍ≤©ÏÑ±-ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûê ÌïòÏúÑ 10Í∞ú Ï£º Í∏∞Ï§Ä')
    # iterate on each region
    for i in offense_name3["offense_name"].unique():
        # filter by region
        df_sub = offense_name3[offense_name3["offense_name"] == i]

        fig_off_asian_bottom.add_shape(
            type="line",
            layer="below",
            y0=df_sub.offense_name.values[0], x0=df_sub.offense_number.values[0],
            y1=df_sub.offense_name.values[1], x1=df_sub.offense_number.values[1], 
        )


    raw_data4 = {'year': [2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020],
                'location_name': list(pd_bottom10_loc.index) * 2,
                'location_number': list(pd_bottom10_loc[2019]) + list(pd_bottom10_loc[2020])}

    location_names4 = pd.DataFrame(raw_data4)

    fig_loc_asian_bottom = px.scatter(location_names4, x="location_number", y="location_name", color="year", color_continuous_scale='Bluered_r',  title = 'Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ±-ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûê ÌïòÏúÑ 10Í∞ú Ï£º Í∏∞Ï§Ä')
    # iterate on each region
    for i in location_names4["location_name"].unique():
        # filter by region
        df_sub = location_names4[location_names4["location_name"] == i]

        fig_loc_asian_bottom.add_shape(
            type="line",
            layer="below",
            # connect the two markers
            ## e.g., y0='Robredo', x0=43.53
            y0=df_sub.location_name.values[0], x0=df_sub.location_number.values[0],
            ## e.g., y1='Marcos', x1=26.60
            y1=df_sub.location_name.values[1], x1=df_sub.location_number.values[1], 
        )
                                           
                          
    st.subheader("ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûê ÏÉÅÏúÑ-ÌïòÏúÑ 10Í∞ú Ï£º, ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í≥ºÍ≤©ÏÑ± ÎπÑÍµêÌïòÍ∏∞üëä")
    st.plotly_chart(fig_off_asian)
    st.plotly_chart(fig_off_asian_bottom)
    
    #Î≤îÏ£Ñ Í≥ºÍ≤©ÏÑ± ÎπÑÍµê
    st.info('''
    * Ï§ëÎ≤îÏ£Ñ, ÏÉÅÏúÑ 10Í∞úÏ£ºÏóêÏÑúÎßå Ï¶ùÍ∞Ä: Í≥ºÍ≤©ÏÑ± 3, 4Ïù∏ Ï§ëÎ≤îÏ£ÑÎäî ÏÇ¨ÎßùÏûê ÏàòÍ∞Ä ÎßéÏïòÎçò ÏÉÅÏúÑ 10Í∞ú Ï£ºÏóêÏÑúÎäî Ï¶ùÍ∞ÄÌïú Î∞òÎ©¥ ÌïòÏúÑ 10Í∞ú Ï£ºÏóêÏÑúÎäî Í∞êÏÜåÌñàÏñ¥Ïöî. ÌïòÏúÑ 10Í∞úÏ£ºÏóêÏÑú Í≥ºÍ≤©ÏÑ± 4Ïùò Î≤îÏ£ÑÎäî ÏïÑÏòà ÏùºÏñ¥ÎÇòÏßÄ ÏïäÏïòÎã§Îäî Í≤ÉÎèÑ Ï£ºÎ™©Ìï¥Ï£ºÏÑ∏Ïöî!
    * Í≤ΩÎ≤îÏ£ÑÎèÑ Îçî ÎÜíÏùÄ ÎπÑÏú®Î°ú Ï¶ùÍ∞Ä: Í≥ºÍ≤©ÏÑ± 2Ïù∏ Î≤îÏ£ÑÏùò Í≤ΩÏö∞ ÌïòÏúÑ 10Í∞ú Ï£ºÏóêÏÑúÎèÑ Îëê Î∞∞ Ï¶ùÍ∞ÄÌñàÏßÄÎßå, ÏÉÅÏúÑ 10Í∞ú Ï£ºÏóêÏÑúÎäî Ï†ÑÎÖÑÎèÑ ÎåÄÎπÑ 171% Ï¶ùÍ∞ÄÌñàÎÑ§Ïöî. ÏΩîÎ°úÎÇò19Í∞Ä Ïã¨ÌñàÎçò ÏßÄÏó≠ÏóêÏÑúÎäî Í≥ºÍ≤©ÏÑ±Ïù¥ ÎÇÆÏùÄ Î≤îÏ£ÑÏôÄ ÎÜíÏùÄ Î≤îÏ£ÑÍ∞Ä Í≥†Î£® ÏïÑÏãúÏïÑÏù∏ÏùÑ ÎåÄÏÉÅÏúºÎ°ú ÌñâÌï¥Ï°åÎã§Îäî Í≤ÉÏùÑ Ïïå Ïàò ÏûàÏñ¥Ïöî.
    ''')
    st.markdown(
              #
              )
      
    st.subheader("Í∑∏Î†áÎã§Î©¥ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä ÏùºÏñ¥ÎÇú Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ±ÏùÄ?üèôÔ∏è")
                                           
    st.plotly_chart(fig_loc_asian)
    st.write(fig_loc_asian_bottom)
    
    #Î≤îÏ£Ñ Ïû•ÏÜå Í≥µÍ∞úÏÑ± ÎπÑÍµê
    st.info('''
    * ÏΩîÎ°úÎÇò19 Ïã¨Ìïú ÏßÄÏó≠Ïù¥ Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ± Îçî ÎÜíÏïÑ: Ïö∞ÏÑ† Í≥µÍ∞úÏÑ±Ïù¥ 5Ïù∏ Ïû•ÏÜåÏóêÏÑú Î∞úÏÉùÌïú ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÎäî ÏÇ¨ÎßùÏûêÏàòÍ∞Ä Í∞ÄÏû• ÎßéÏùÄ 10Í∞úÏ£ºÏóêÏÑú Ï¶ùÍ∞ÄÌïú Î∞òÎ©¥, ÏÇ¨ÎßùÏûêÏàòÍ∞Ä Í∞ÄÏû• Ï†ÅÏùÄ 10Í∞úÏ£ºÏóêÏÑúÎäî Ïò§ÌûàÎ†§ Í∞êÏÜåÌñàÏñ¥Ïöî. Í≥µÍ∞úÏÑ± 4Ïù∏ Ïû•ÏÜåÏóêÏÑú ÏùºÏñ¥ÎÇú ÌòêÏò§ Î≤îÏ£ÑÏùò Ï¶ùÍ∞ÄÏú®ÏùÄ ÏÉÅÏúÑ 10Í∞ú Ï£ºÏóêÏÑúÎäî Ï†ÑÎÖÑÎèÑ ÎåÄÎπÑ 80%, ÌïòÏúÑ 10Í∞ú Ï£ºÏóêÏÑúÎäî 16%ÏòÄÍ≥†Ïöî. ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûêÍ∞Ä ÎßéÏùÄ Ï£ºÏóêÏÑú Îçî Í≥µÍ∞úÏÑ± ÎÜíÏùÄ ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä Ïù¥Ï†ÑÏóê ÎπÑÌï¥ ÎßéÏù¥ Î∞úÏÉùÌñàÏùåÏùÑ Ïïå Ïàò ÏûàÏñ¥Ïöîüßë‚Äç‚öñÔ∏è
    ''')


    st.markdown("""
    ##### ‚úãÏû†Íπê! Ïó¨Í∏∞ÍπåÏßÄ Ï†ïÎ¶¨ ‚úã
    * ÎØ∏Íµ≠ Ï†ÑÏó≠Ïóê Ïù¥Ïñ¥ ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûêÍ∞Ä ÎßéÏïòÎçò 10Í∞ú Ï£ºÏôÄ Í∑∏Î†áÏßÄ ÏïäÏùÄ 10Í∞ú Ï£ºÎ•º ÎπÑÍµêÌï¥Î¥§ÎäîÎç∞Ïöî, ÏÉÅÏúÑ 10Í∞ú Ï£ºÏóêÏÑú Î∞úÏÉùÌïú Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±Ïù¥ ÌïòÏúÑ 10Í∞ú Ï£ºÎ≥¥Îã§ ÎçîÏö± ÎÜíÍ≤å ÎÇòÌÉÄÎÇ¨ÏäµÎãàÎã§.
    * Î≤îÏ£Ñ Ïû•ÏÜåÏùò Í≥µÍ∞úÏÑ± ÎòêÌïú, ÏΩîÎ°úÎÇò19Î•º Ï†ÑÌõÑÎ°ú Í∑∏ ÌîºÌï¥Í∞Ä Ïã¨ÌñàÎçò ÏßÄÏó≠ÏóêÏÑú ÎçîÏö± Ï¶ùÍ∞ÄÌïú Í≤ÉÏùÑ Î≥º Ïàò ÏûàÏóàÏñ¥Ïöî. 
    * Í≤∞Î°†Ï†ÅÏúºÎ°ú ÏΩîÎ°úÎÇò19Í∞Ä Ïã¨ÌñàÎçò Ï£ºÏùò ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ ÏñëÏÉÅÏù¥, 2019ÎÖÑÍ≥º 2020ÎÖÑ ÏÇ¨Ïù¥ ÎçîÏö± Ïú†ÏùòÎØ∏ÌïòÍ≤å Î≥ÄÌôîÌñàÏùåÏùÑ Ïïå Ïàò ÏûàÏñ¥Ïöî. 
    Ïù¥Î•º ÌÜµÌï¥, ÏΩîÎ°úÎÇò 19Ïùò Î∞úÏÉùÍ≥º ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Ïã¨Í∞ÅÏÑ± ÏÇ¨Ïù¥ Í∞ïÌïú ÏÉÅÍ¥ÄÍ¥ÄÍ≥ÑÍ∞Ä ÏûàÏùåÏùÑ Î≥¥Ïùº Ïàò ÏûàÏäµÎãàÎã§üìäüñäÔ∏è
    """)

    st.markdown('''
    -----------
                ''')


elif add_radio == "üìà Ìä∏ÎüºÌîÑ Îì±Ïû•! ÌòêÏò§ Î≤îÏ£ÑÎèÑ ÏÉÅÏäπ?":

  # section 4: Ïó∞ÏÑ§Î¨∏ Ìä∏Î¶¨Îßµ
  st.markdown('''
  ## üìà Ìä∏ÎüºÌîÑ Îì±Ïû•! ÌòêÏò§ Î≤îÏ£ÑÎèÑ ÏÉÅÏäπ?
              ''')


  st.warning('''
  * Ìä∏ÎüºÌîÑ ÏßëÍ∂å ÏãúÍ∏∞, Î∞îÏù¥Îì† ÏßëÍ∂å ÏãúÍ∏∞ Íµ≠Ï†ï Ïó∞ÏÑ§(State of the Union Speech) ÌÇ§ÏõåÎìú Î∂ÑÏÑùÏùÑ Ìï¥Î¥§Ïñ¥Ïöî. 
  * 1ÎÖÑÏóê Ìïú Î≤à ÏûàÎäî Íµ≠Ï†ï Ïó∞ÏÑ§ÏùÄ ÎåÄÌÜµÎ†πÏù¥ ÏßÅÏ†ë Íµ≠Í∞Ä ÏÉÅÌô©Í≥º Ï†ïÏ±Ö Í∏∞Ï°∞Î•º ÏÑ§Î™ÖÌïòÎäî Îã¥ÌôîÏù∏ ÎßåÌÅº, Ìï¥Îãπ Îã¥ÌôîÏóêÏÑú ÎÇòÌÉÄÎÇú ÌÇ§ÏõåÎìúÎì§ÏùÄ ÎãπÏãúÏùò ÏÇ¨ÌöåÏ†Å ÏÉÅÌô©ÏùÑ ÏÑ§Î™ÖÌïòÎäî Îç∞ ÏûàÏñ¥ Îß§Ïö∞ Ï§ëÏöîÌï¥Ïöî.
  * Î≥¥ÎùºÏÉâ Ìä∏Î¶¨ÎßµÏùÄ ÏûêÏ£º Îì±Ïû•Ìïú ÌÇ§ÏõåÎìúÎ•º ÎπàÎèÑÏàòÎåÄÎ°ú Í∑∏Î¶∞ Í≤ÉÏù¥Í≥†, ÏïÑÎûòÏùò Ìä∏Î¶¨ÎßµÏùÄ Í∑∏Ï§ëÏóêÏÑúÎèÑ ÌòêÏò§ Î≤îÏ£Ñ Í¥ÄÎ†® Îã®Ïñ¥Îì§ÏùÑ Î™®ÏïÑÎÜìÏùÄ Í≤ÉÏù¥ÏóêÏöî! 
  ''')

                                           
  #*stopwords ÏóÖÎç∞Ïù¥Ìä∏
  #words filtered
  from nltk.corpus import stopwords
  stop_words = set(stopwords.words('english'))
  stop_words.update(['.', ',', '"', "'", '?', '!',"''",'``', '', '', ':', ';', '‚Äô', '(', ')','`','[', ']',
  '--','‚Äì', '‚Äú', '‚Äù', '{', '}','_', "'\\n", "\n", "‚Äî", '%', '#', '###', 'u', 'wa', '$', 'america', 'american', 
  'americans', 'people', 'year', 'ha', 'also', 'tonight']) #Îß§ÎÖÑ Î∞òÎ≥µÎêòÎäî ÏùòÎ°ÄÏ†Å Îã®Ïñ¥Îì§ÏùÄ Ï†úÏô∏.


  @st.cache(suppress_st_warning=True)
  def speech_keywords_counter(url):
      doc = ""
      with urllib.request.urlopen(url) as url:
          doc = url.read()

      soup = BeautifulSoup(doc, "html.parser")
      speech = soup.find_all("p", class_="paragraph inline-placeholder")


      sentences = []
      for i in range(len(speech)):
          sentences.append(speech[i].text.strip())

      lemma = nltk.wordnet.WordNetLemmatizer()
      speech_tokens = []
      for sentence in sentences:
          speech_tokens.append(nltk.word_tokenize(sentence))

      speech_lemma = []

      for token in speech_tokens :
          for tok in token:
              speech_lemma.append(lemma.lemmatize(tok))

      #stopwords ÏúÑÏóê Ìï¥Îë†       
      words_filtered = [word.lower() for word in speech_lemma if word.lower() not in stop_words]
      speech_cnt = Counter(words_filtered)

      return speech_cnt

  # Ï†ÑÏ≤¥ Î¶¨Ïä§Ìä∏ + ÌòêÏò§ Î≤îÏ£Ñ Í¥ÄÎ†® Îã®Ïñ¥Îì§ ÎπàÎèÑÏàò ÏÑ∏Îäî Î¶¨Ïä§Ìä∏ ÎßåÎìúÎäî Ìï®Ïàò Ï∂îÍ∞Ä
  @st.cache(allow_output_mutation=True)
  def count_words_total(counter):
      hate_words_list = ['isis', 'islamic', 'terrorist', 'asian', 'border', 'race', 'racism', 'african-american', 'immigration', 'china', 'threat']
      hate_words_dict = {}

      counter_df = pd.DataFrame(counter.most_common(), columns = ['word', 'count'])
      for w in counter_df['word']:
          if w in hate_words_list:
              hate_words_dict[w] = len(counter_df[counter_df['word'] == w])

      hate_words = list(hate_words_dict.keys())
      hate_words_count = list(hate_words_dict.values())

      counter_df_hate = pd.DataFrame({'word': hate_words, 'count': hate_words_count, 'type': hate_words_count})
      counter_df_hate['type'] = 'hate crime word'

      return counter_df_hate

  ############### 2017 #################
  url_2017 = "https://edition.cnn.com/2017/02/28/politics/donald-trump-speech-transcript-full-text/index.html"
  word_2017 = pd.DataFrame(speech_keywords_counter(url_2017).most_common(70), columns = ['word', 'count'])
  hate_2017 = count_words_total(speech_keywords_counter(url_2017))

  ##############2018##############
  url_2018 = "https://edition.cnn.com/2018/01/30/politics/2018-state-of-the-union-transcript/index.html"
  word_2018 = pd.DataFrame(speech_keywords_counter(url_2018).most_common(70), columns = ['word', 'count'])
  hate_2018 = count_words_total(speech_keywords_counter(url_2018))

  ##############2019##############
  url_2019 = "https://edition.cnn.com/2019/02/05/politics/donald-trump-state-of-the-union-2019-transcript/index.html"
  word_2019 = pd.DataFrame(speech_keywords_counter(url_2019).most_common(70), columns = ['word', 'count'])
  hate_2019= count_words_total(speech_keywords_counter(url_2019))

  ##############2020##############
  url_2020 = "https://edition.cnn.com/2020/02/04/politics/trump-2020-state-of-the-union-address/index.html"
  word_2020 = pd.DataFrame(speech_keywords_counter(url_2020).most_common(70), columns = ['word', 'count'])
  hate_2020 = count_words_total(speech_keywords_counter(url_2020))

  ###################2021################# ÏñòÎßå ÎßÅÌÅ¨Í∞Ä Îã¨ÎùºÏÑú Îã§Î•¥Í≤å Ìï®..
  url_2021 = "https://www.whitehouse.gov/briefing-room/speeches-remarks/2022/03/01/remarks-of-president-joe-biden-state-of-the-union-address-as-delivered/"
  doc_2021 = ""
  with urllib.request.urlopen(url_2021) as url:
      doc_2021 = url.read()

  soup = BeautifulSoup(doc_2021, "html.parser")

  s_2021 = soup.find_all("p")

  sentences_2021 = []
  for i in range(len(s_2021)):
      sentences_2021.append(s_2021[i].text.strip().replace('\xa0', ''))

  #sentences_2021

  lemma = nltk.wordnet.WordNetLemmatizer()
  s_2021_tokens = []
  for sentence in sentences_2021:
      s_2021_tokens.append(nltk.word_tokenize(sentence))

  s_2021_lemma = []

  for token in s_2021_tokens :
      for tok in token:
          s_2021_lemma.append(lemma.lemmatize(tok))

  #stopwords ÏúÑÏóê Ìï¥Îë†       
  words_filtered_2021 = [word.lower() for word in s_2021_lemma if word.lower() not in stop_words]

  s_2021_cnt = Counter(words_filtered_2021)
  word_2021 = pd.DataFrame(s_2021_cnt.most_common(70), columns = ['word', 'count'])
  hate_2021 = count_words_total(s_2021_cnt)

  ##############2022##############
  url_2022 = "https://edition.cnn.com/2022/03/01/politics/biden-state-of-the-union-2022-transcript/index.html"
  word_2022 = pd.DataFrame(speech_keywords_counter(url_2022).most_common(70), columns = ['word', 'count'])
  hate_2022 = count_words_total(speech_keywords_counter(url_2022))


  select_year = st.selectbox('ÌôïÏù∏Ìï† Ïó∞ÎèÑÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî', ('2017', '2018', '2019', '2020', '2021', '2022'))

  ## *Ìä∏Î¶¨Îßµ Í∑∏Î¶¨Îäî Ìï®Ïàò!
  #from plotly.subplots import make_subplots

  @st.cache
  def draw_treemap(word_df):
      fig = px.treemap(
          word_df, path=[px.Constant("total"), 'word'],
          values = 'count',
          color = 'count',
          color_continuous_scale='Purples',
          color_continuous_midpoint = 0, title='State of the Union Speech Keywords'
      )
      fig.update_traces(root_color="lightgrey")
      fig.update_layout(font_size=15, margin = dict(t=50, l=25, r=25, b=25))

      return fig

  @st.cache
  def draw_treemap_hate(word_df):
      fig = px.treemap(
          word_df, path=[px.Constant("total"),  'word'],
          values = 'count',
          color_discrete_map= {'word' : 'red'},
          color_continuous_midpoint = 0, title='Hate Crime Keywords'
      )
      fig.update_traces(root_color="lightgrey")
      fig.update_layout(font_size=20, margin = dict(t=50, l=25, r=25, b=25))

      return fig

  #color_continuous_midpoint

  if select_year == '2017':
      st.plotly_chart(draw_treemap(word_2017), use_container_width=True)
      st.plotly_chart(draw_treemap_hate(hate_2017), use_container_width=True)
  elif select_year == '2018':
      st.plotly_chart(draw_treemap(word_2018))
      st.plotly_chart(draw_treemap_hate(hate_2018))
  elif select_year == '2019':
      st.plotly_chart(draw_treemap(word_2019))
      st.plotly_chart(draw_treemap_hate(hate_2019))
  elif select_year == '2020':
      st.plotly_chart(draw_treemap(word_2020))
      st.plotly_chart(draw_treemap_hate(hate_2020))
  elif select_year == '2021':
      st.plotly_chart(draw_treemap(word_2021))
      st.plotly_chart(draw_treemap_hate(hate_2021))
  elif select_year == '2022':
      st.plotly_chart(draw_treemap(word_2022))
      st.plotly_chart(draw_treemap_hate(hate_2022))


  st.info('''
  * 2016ÎÖÑÎ∂ÄÌÑ∞ 2022ÎÖÑ, Íµ≠Ï†ï Ïó∞ÏÑ§ ÎπÑÍµêÌï¥Î≥¥Îãà: ÎπàÎèÑÏàòÎ•º ÎπÑÍµêÌï¥Î≥¥Îãà, Ìä∏ÎüºÌîÑ ÏãúÍ∏∞ÏóêÎäî race, islamic, isis, African-AmericanÍ≥º Í∞ôÏùÄ ÏßÅÏ†ëÏ†ÅÏù∏ Ïù∏Ï¢Ö Î∞è ÎØºÏ°± Ïñ∏Í∏âÏù¥ ÎßéÏïòÎçò Î∞òÎ©¥ Î∞îÏù¥Îì† ÏãúÍ∏∞ÏóêÎäî Í∑∏Îü∞ ÌÇ§ÏõåÎìúÍ∞Ä Îì±Ïû•ÌïòÏßÄ ÏïäÍ≥† immigration, threat Îì±Ïùò Îã®Ïñ¥Îßå Í≥µÌÜµÏ†ÅÏúºÎ°ú Ïó∞ÏÑ§Ïóê ÏÇ¨Ïö©ÎêêÏñ¥Ïöî. 
  * Ïù¥Ïä¨Îûå Í¥ÄÎ†® Ïñ∏Í∏âÏù¥ ÌäπÌûà ÎßéÏïÑ: Ìä∏ÎüºÌîÑ ÏãúÍ∏∞ Íµ≠Ï†ïÏó∞ÏÑ§ÏóêÎäî Îã§Î•∏ Í≤ÉÎ≥¥Îã§ÎèÑ terroristÎùºÎäî Îã®Ïñ¥ÏôÄ Ïù¥Ïä¨Îûå Í¥ÄÎ†® Îã®Ïñ¥Ïù∏ ISIS, IslamicÏù¥ ÏûêÏ£º Ìï®Íªò Îì±Ïû•ÌñàÏñ¥Ïöî. 2020ÎÖÑÍπåÏßÄ Î¨¥Ïä¨Î¶º ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä Íæ∏Ï§ÄÌûà ÎπÑÏ§ëÏùÑ Ï∞®ÏßÄÌñàÎçò Í≤ÉÍ≥º Î¨¥Í¥ÄÌïòÏßÄ ÏïäÏïÑÎ≥¥ÏûÖÎãàÎã§. 
  * Î∞îÏù¥Îì† ÏãúÍ∏∞ÏóêÎèÑ terroristÎùºÎäî Îã®Ïñ¥Îäî Íµ≠Ï†ï Ïó∞ÏÑ§Ïóê ÏÇ¨Ïö©ÎêêÏßÄÎßå, ÌäπÏ†ï Ïù∏Ï¢ÖÍ≥º ÎØºÏ°±ÏùÑ ÏΩï ÏßëÏñ¥ Ïñ∏Í∏âÌïòÏßÄÎäî ÏïäÏïòÎã§Îäî Ï∞®Ïù¥Ï†êÏù¥ ÏûàÏñ¥Ïöî.
  ''')


  st.markdown('''
  ##### üí¨ÎßàÎ¨¥Î¶¨ÌïòÎäî Îßêüí¨
  üìç Ìä∏ÎüºÌîÑ ÎãπÏÑ† ÏãúÍ∏∞Î•º Í∏∞Ï†êÏúºÎ°ú Ï†ÑÏ≤¥ ÌòêÏò§ Î≤îÏ£ÑÍ∞Ä Ï¶ùÍ∞ÄÌñàÏùåÏùÄ Î¨ºÎ°†,
  Ìä∏ÎüºÌîÑ ÏßëÍ∂å ÏãúÍ∏∞ÏóêÎäî ÎåÄÌÜµÎ†π Íµ≠Ï†ïÏó∞ÏÑ§ÏóêÏÑúÎèÑ Ïù∏Ï¢Ö Í¥ÄÎ†® Î¨∏Ï†úÍ∞Ä ÎçîÏö± ÏûêÏ£º Îì±Ïû•ÌñàÏñ¥Ïöî.
  ÎòêÌïú ÌäπÏ†ï Ïù∏Ï¢ÖÏóê Í¥ÄÌïú Î∂ÄÏ†ïÏ†ÅÏù∏ Í∞êÏ†ïÏùÑ Ïú†Î∞úÌï† Ïàò ÏûàÎäî Îã®Ïñ¥ÎèÑ Î∞îÏù¥Îì† ÏãúÍ∏∞Ïóê ÎπÑÌï¥ Ìõ®Ïî¨ ÏûêÏ£º Îì±Ïû•ÌñàÎãµÎãàÎã§.
  Ï¶â Ìä∏ÎüºÌîÑÏùò Îì±Ïû•Í≥º Ï†ÑÎ∞òÏ†ÅÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Ï¶ùÍ∞ÄÍ∞Ä ÎÇòÎ¶ÑÏùò ÏÉÅÍ¥ÄÍ¥ÄÍ≥ÑÎ•º ÏßÄÎãàÍ≥† ÏûàÎã§Í≥† Ï†ïÎ¶¨Ìï¥Î≥º Ïàò ÏûàÍ≤†Ïñ¥Ïöî!

  üìç ÏΩîÎ°úÎÇò19Í∞Ä Ï∞ΩÍ∂êÌïú Ïù¥ÌõÑ, ÎØ∏Íµ≠ ÎÇ¥ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Ïã¨Í∞ÅÏÑ±ÏùÄ Í∑∏Ï†ÑÍ≥º ÎπÑÍµêÌï¥ Ïã¨ÌôîÎêêÏäµÎãàÎã§. 
  ÌäπÌûà ÏΩîÎ°úÎÇò19Í∞Ä ÏÉÅÎ•ôÌïú ÏãúÍ∏∞ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Í±¥ÏàòÎäî Í∑πÏóê Îã¨ÌñàÍ≥†, Í≥ºÍ≤©ÏÑ±ÏùÄ Î¨ºÎ°† Í≥µÍ∞úÏ†ÅÏù∏ Ïû•ÏÜåÏóêÏÑú Î≤åÏñ¥ÏßÄÎäî Î≤îÏ£ÑÎèÑ Ïú†ÏùòÎØ∏ÌïòÍ≤å Ï¶ùÍ∞ÄÌñàÏñ¥Ïöî‚¨ÜÔ∏è

  üìç ÏΩîÎ°úÎÇò19ÏôÄ ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Í¥ÄÍ≥ÑÎäî ÏΩîÎ°úÎÇò19 ÏÇ¨ÎßùÏûêÍ∞Ä ÎßéÏïòÎçò 10Í∞ú Ï£ºÏôÄ ÏÇ¨ÎßùÏûêÍ∞Ä Ï†ÅÏóàÎçò 10Í∞ú Ï£ºÏùò ÎπÑÍµêÎ•º ÌÜµÌï¥ Í∞ÄÏû• Î∂ÑÎ™ÖÌûà Î≥º Ïàò ÏûàÏóàÏñ¥Ïöî. 
  ÏÇ¨ÎßùÏûê ÏàòÍ∞Ä ÎßéÏùÄ ÏßÄÏó≠ÏùºÏàòÎ°ù ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£Ñ Ïàò, Î≤îÏ£ÑÏùò Í≥ºÍ≤©ÏÑ±, Í≥µÍ≤©ÏÑ±Ïù¥ 2020ÎÖÑ Îçî ÎÜíÏùÄ ÎπÑÏú®Î°ú Ï¶ùÍ∞ÄÌñàÍ≥†,
   ÎÇÆÏùÄ ÏßÄÏó≠ÏùºÏàòÎ°ù ÏΩîÎ°úÎÇò19Ïùò Îì±Ïû• Ïó¨Î∂ÄÏôÄ ÏÉÅÍ¥ÄÏóÜÏù¥ Î≤îÏ£Ñ ÏñëÏÉÅÏù¥ Ïú†ÏßÄÎêòÍ±∞ÎÇò Ïò§ÌûàÎ†§ ÌïòÎùΩÌïòÎäî Î™®ÏäµÏùÑ Î≥¥ÏòÄÎãµÎãàÎã§.
   ÏöîÏª®ÎåÄ ÏΩîÎ°úÎÇò19Ïùò Îì±Ïû•Í≥º ÏïÑÏãúÏïÑÏù∏ ÌòêÏò§ Î≤îÏ£ÑÏùò Ïã¨Í∞ÅÏÑ±ÏùÄ Ï†ïÏùò Í¥ÄÍ≥Ñ(‚ûï)Ïóê ÏûàÎã§Í≥† ÎßêÌï† Ïàò ÏûàÏäµÎãàÎã§!
          ''')

