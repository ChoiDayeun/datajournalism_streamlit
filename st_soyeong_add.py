# module/package
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px #ì¼ë‹¨ ì´ê±° ì´ìš©í•´ ê¸°ë³¸ ê·¸ë˜í”„ ê·¸ë¦¼
import nltk 
import random
import plotly.graph_objects as go 
import urllib.request

from PIL import Image
from bs4 import BeautifulSoup
from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag

nltk.download('omw-1.4')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
nltk.download('wordnet')


# set-page
st.set_page_config(page_icon="ğŸ—½",
                   page_title="ë°ì´í„°ì €ë„ë¦¬ì¦˜-2ì¡°")
add_radio = st.sidebar.radio("Table of Contents", ("ğŸ“… ë¯¸êµ­ì˜ í˜ì˜¤ ë²”ì£„, 2015ë…„ë¶€í„° 2020ë…„ê¹Œì§€", "ğŸš«ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, ì¢€ ë” ìì„¸íˆ ì•Œì•„ë³¼ê¹Œ?", "ğŸ”ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, ì§€ì—­ìœ¼ë¡œ ì¢í˜€ ë³´ì!", "ğŸ“ˆ íŠ¸ëŸ¼í”„ ë“±ì¥! í˜ì˜¤ ë²”ì£„ë„ ìƒìŠ¹?"))

# header
st.markdown("""
# ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, í™•ì‚°ê³¼ ì‹¬í™”: ì½”ë¡œë‚˜19 ì „í›„ ë¯¸êµ­ì˜ í˜ì˜¤ ë²”ì£„ë¥¼ ì¡°ëª…í•˜ë‹¤ğŸ’¡
* ë°ì´í„°ì €ë„ë¦¬ì¦˜: ì˜¤ì†Œì˜, ì´í˜œì •, ìµœë‹¤ì—°
""") 

# introduce
st.error('''
â“ì½”ë¡œë‚˜19ëŠ” ë¯¸êµ­ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì³¤ì„ê¹Œ?

   âœ…2019ë…„ê³¼ 2020ë…„ì˜ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜, ê³¼ê²©ì„±, ê³µê°œì„± ë¹„êµí•˜ê¸°
    
â“ì½”ë¡œë‚˜19 í”¼í•´ê°€ ì‹¬í–ˆë˜ ì£¼ì—ì„œëŠ” í˜ì˜¤ ë²”ì£„ë„ ì‹¬í–ˆì„ê¹Œ?

   âœ…ì½”ë¡œë‚˜19 í™•ì§„ì/ì‚¬ë§ì ìˆ˜ ìƒìœ„ 10ê°œ ì£¼ì™€ í•˜ìœ„ 10ê°œ ì£¼ ë²”ì£„ ì–‘ìƒ ë“¤ì—¬ë‹¤ ë³´ê¸°

â“íŠ¸ëŸ¼í”„ì˜ ë“±ì¥ì´ í˜ì˜¤ ë²”ì£„ ì–‘ìƒì— ê°€ì ¸ì˜¨ ë³€í™”ëŠ”?

   âœ…ë¯¸êµ­ êµ­ì •ì—°ì„¤ í‚¤ì›Œë“œ ë¶„ì„í•˜ê¸°
           ''')   
 
st.text_area('data', '''Raw data: 
CNN Politics State of the Union: 2017 ~ 2021,
The Hate Crime Statistics Program of the FBI Uniform Crime Reporting (UCR) Program
             ''', label_visibility = "hidden") 

st.markdown("""
----------------
""")

fbi =  pd.read_csv("fbi_data_edited.csv", low_memory=False)
df = pd.DataFrame(fbi, columns=['DATA_YEAR', 'BIAS_DESC'])


if add_radio == "ğŸ“… ë¯¸êµ­ì˜ í˜ì˜¤ ë²”ì£„, 2015ë…„ë¶€í„° 2020ë…„ê¹Œì§€":
  # section1
  st.markdown("""
  ## ğŸ“… ë¯¸êµ­ì˜ í˜ì˜¤ ë²”ì£„, 2015ë…„ë¶€í„° 2020ë…„ê¹Œì§€
  """)

  st.markdown('''
              #
              ''')

  st.subheader("ì ì  ì¦ê°€í•˜ëŠ” í˜ì˜¤ ë²”ì£„ ë°œìƒ ê±´ìˆ˜")



  # section1-1: ì „ì²´í˜ì˜¤/ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„

  #Anti Asian ì¦ê°€ë§Œ ë³´ì—¬ì£¼ëŠ” ê·¸ë˜í”„
  options_2 = st.radio('ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”', ['ì „ì²´ í˜ì˜¤ ë²”ì£„', 'ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„'])
  df_2015 = df[(df['DATA_YEAR'] == 2015)]
  df_2016 = df[(df['DATA_YEAR'] == 2016)]
  df_2017 = df[(df['DATA_YEAR'] == 2017)]
  df_2018 = df[(df['DATA_YEAR'] == 2018)]
  df_2019 = df[(df['DATA_YEAR'] == 2019)]
  df_2020 = df[(df['DATA_YEAR'] == 2020)]

  #ìƒˆë¡œìš´ df: ì—°ë„ë³„ ì „ì²´ / ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ë²”ì£„ count. index: ì—°ë„, columns: ê°’
  #ì „ì²´
  all_hates = [len(df_2015['BIAS_DESC']), len(df_2016['BIAS_DESC']), len(df_2017['BIAS_DESC']), len(df_2018['BIAS_DESC']),
              len(df_2019['BIAS_DESC']), len(df_2020['BIAS_DESC'])]
  df_all = pd.DataFrame(all_hates, index = ['2015', '2016', '2017', '2018', '2019', '2020'])

  all_fig = px.line(df_all, title = "All Hate Crime Cases in the US", markers=True)
  all_fig.update_layout(xaxis = dict({"title" : "Year"}), yaxis = dict({"title" : "Counted Cases"}), showlegend = False)

  #ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ë²”ì£„

  asian_hates = [len(df_2015.loc[df_2015['BIAS_DESC'] == 'Anti-Asian']), len(df_2016.loc[df_2016['BIAS_DESC'] == 'Anti-Asian']), 
              len(df_2017.loc[df_2017['BIAS_DESC'] == 'Anti-Asian']), len(df_2018.loc[df_2018['BIAS_DESC'] == 'Anti-Asian']),
              len(df_2019.loc[df_2019['BIAS_DESC'] == 'Anti-Asian']), len(df_2020.loc[df_2020['BIAS_DESC'] == 'Anti-Asian'])]
  df_asian_edit = pd.DataFrame(asian_hates, index = ['2015', '2016', '2017', '2018', '2019', '2020'])
  asian_fig = px.line(df_asian_edit, title = "Asian Hate Crime Cases in the US", markers=True)
  asian_fig.update_layout(xaxis = dict({"title" : "Year"}), yaxis = dict({"title" : "Counted Cases"}), showlegend = False)

  if options_2 == 'ì „ì²´ í˜ì˜¤ ë²”ì£„':
      st.plotly_chart(all_fig)
  elif options_2 == 'ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„':
      st.plotly_chart(asian_fig)

  st.info('''
  * ì „ì²´ í˜ì˜¤ ë²”ì£„ ê¾¸ì¤€íˆ ì¦ê°€: ë¯¸êµ­ ì „ì—­ì˜ í˜ì˜¤ ë²”ì£„ ë¹ˆë„ìˆ˜ë¥¼ ì‹œê°í™”í•œ ê²°ê³¼, 2015ë…„ë¶€í„° 2020ë…„ê¹Œì§€ ì¦ê°€í•˜ê³  ìˆëŠ” ëª¨ìŠµì„ ë³¼ ìˆ˜ ìˆì–´ìš”. 
  * ë¬´ì—‡ì´ ê¸°ì ?: íŠ¸ëŸ¼í”„ ì „ ëŒ€í†µë ¹ì˜ ë‹¹ì„ ì´ í™•ì •ëœ 2016ë…„, ì½”ë¡œë‚˜19ê°€ ë°œìƒí•œ 2020ë…„ì„ ê¸°ì ìœ¼ë¡œ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ê°€ ë‘ë“œëŸ¬ì§€ê²Œ ì¦ê°€í–ˆì–´ìš”! 
               ''')

  st.markdown('''
              #
              ''')
  # section1-2: ì „ì²´ í˜ì˜¤ ë²”ì£„ ëŒ€ë¹„ ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„ ë¹„ìœ¨ + ë§¤íŠ¸ë¦­ìŠ¤

  all_asian_ratio = []
  for i in range(len(asian_hates)):
      all_asian_ratio.append((int(asian_hates[i]) / int(all_hates[i])) * 100) #ì•„ì‹œì•„ì¸ í˜ì˜¤ë²”ì£„ ê±´ìˆ˜ / ì „ì²´ í˜ì˜¤ë²”ì£„ ê±´ìˆ˜ * 100 : ë¹„ìœ¨ (ë§ë‚˜?)

  df_compare = pd.DataFrame(all_asian_ratio, index = ['2015', '2016', '2017', '2018', '2019', '2020'])
  compare_fig = px.bar(df_compare, title = "Asian Hate Crime Cases Ratio Out of All Hate Crimes")
  compare_fig.update_layout(xaxis = dict({"title" : "Year"}), yaxis = dict({"title" : "Relatvie proportion(%)"}), showlegend = False)

  cols = st.columns((1, 1, 3))


  cols[0].metric("","", "")
  cols[0].write("Crime Cases")
  cols[0].metric("2019", "188", "11.5%")
  cols[0].metric("","", "")
  cols[0].write("Crime Proportion")
  cols[0].metric("2019", "2.38%", "0.3%p")

  cols[1].metric("","", "")
  cols[1].metric("","", "")
  cols[1].metric("2020", "323", "26.4%")
  cols[1].metric("","", "")
  cols[1].metric("","", "")
  cols[1].metric("2020", "3.14%", "0.76%p")

  cols[2].plotly_chart(compare_fig, use_container_width = True)


  st.info('''
  * â€˜ì½”ì‹œêµ­â€™ì˜ ë„ë˜: ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ë¹ˆë„ìˆ˜ëŠ” í•œë²ˆë„ êº¾ì´ì§€ ì•Šê³  ìƒìŠ¹ì„¸ì— ìˆì—ˆëŠ”ë°ìš”ğŸ“ˆ
  íŠ¹íˆ íŒ¬ë°ë¯¹ì´ ì‹œì‘ëœ 2020ë…„ì˜ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ëŠ” ì „ë…„ë„ ëŒ€ë¹„ 55% ì¦ê°€í–ˆìŠµë‹ˆë‹¤. 5ë…„ ì „ì¸ 2015ë…„ì— ë¹„êµí–ˆì„ ë•ŒëŠ” 283% ê°€ëŸ‰ ì¦ê°€í•œ ìˆ˜ì¹˜ì—ìš”.
   ë™ì¼í•œ ê¸°ê°„ ì „ì²´ í˜ì˜¤ ë²”ì£„ëŠ” 30% ì¦ê°€í•œ ê²ƒê³¼ ë¹„êµí•´ë„ ì—„ì²­ë‚œ ë³€í™”ì£ ? 
          ''')    

  st.markdown('''
              #
              #
              ''')

  # section1-3: ì›ê·¸ë˜í”„
  st.subheader("ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì˜ ë¹„ì¤‘ì€ ì–´ë–»ê²Œ ë³€í™”í–ˆì„ê¹Œ?")

  tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["2015", "2016", "2017", "2018", "2019", "2020"])

  @st.cache
  def crime_pie_chart(filename):
      crime_data_count = pd.read_csv(filename)
      crime_data_count['number'].astype(int)
      cdc_2015 = crime_data_count['number'].tolist() #ëŒ€ìƒ ì¸ì¢…ë³„ ë²”ì£„ìˆ˜ ë‹´ì€ ë¦¬ìŠ¤íŠ¸.
      idx_2015 = list(crime_data_count['race'])

      return crime_data_count


  with tab1:
      st.header("2015")
      fig_2015 = px.pie(crime_pie_chart("hate_crime_race.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2015.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2015)

  with tab2:
      st.header("2016")
      fig_2016 = px.pie(crime_pie_chart("hate_crime_race_2016.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2016.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2016)


  with tab3:
      st.header("2017")
      fig_2017 = px.pie(crime_pie_chart("hate_crime_race_2017.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2017.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2017)

  with tab4:
      st.header("2018")
      fig_2018 = px.pie(crime_pie_chart("hate_crime_race_2018.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2018.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2018)


  with tab5:
      st.header("2019")
      fig_2019 = px.pie(crime_pie_chart("hate_crime_race_2019.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2019.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2019)

  with tab6:
      st.header("2020")
      fig_2020 = px.pie(crime_pie_chart("hate_crime_race_2020.csv"), values = 'number', names = 'race', color_discrete_sequence=px.colors.sequential.RdBu)
      fig_2020.update_traces(pull=[0, 0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      st.plotly_chart(fig_2020)

  st.caption('*íŠ¹ì • ëŒ€ìƒì„ í–¥í•œ í˜ì˜¤ ë²”ì£„ê°€ 50ê±´ ì´í•˜ ë°œìƒí•œ ê²½ìš°ëŠ” ê¸°íƒ€ë¡œ í†µí•©')

  st.info("""
  * ë§¤ë…„ 100ê±´ ì´ìƒ ë°œìƒ: ë¯¸êµ­ ì „ì—­ì˜ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ë¥¼ í”¼í•´ëŒ€ìƒ(victims)ë³„ë¡œ ë¶„ë¥˜í•´ë´¤ë”ë‹ˆ,ì•„ì‹œì•„ì¸ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” í˜ì˜¤ ë²”ì£„ëŠ” 2015ë…„ë¶€í„° 2020ë…„ê¹Œì§€ ë§¤ë„Œ 100ê±´ ë„˜ê²Œ ë°œìƒí–ˆì–´ìš”. ê°ˆìˆ˜ë¡ ê±´ìˆ˜, ë¹„ì¤‘ ëª¨ë‘ ëŠ˜ì–´ë‚˜ê³  ìˆëŠ” ëª¨ìŠµì„ ë³´ì´ë„¤ìš”.
  * 2020ë…„ ì—­ëŒ€ ìµœê³ ì¹˜: íŠ¹íˆ ì½”ë¡œë‚˜19ê°€ ë°œìƒí•œ 2020ë…„ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ëŠ” ì „ì²´ í˜ì˜¤ ë²”ì£„ ì¤‘ 3.13%ë¥¼ ì°¨ì§€í•˜ë©° ìµœê³ ì¹˜ë¥¼ ê¸°ë¡í–ˆì–´ìš”. 
  """)

  st.markdown('''
              #
  --------
  #
              ''')



elif add_radio == "ğŸš«ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, ì¢€ ë” ìì„¸íˆ ì•Œì•„ë³¼ê¹Œ?":
  # section2
  st.markdown("""
  ##  ğŸš«ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, ì¢€ ë” ìì„¸íˆ ì•Œì•„ë³¼ê¹Œ?
  """)

  st.subheader("ìš°ë¦¬ëŠ” ë²”ì£„ì˜ ì‹¬ê°ì„±ì„ ì•„ë˜ì˜ ì„¸ ì²™ë„ë¡œ í™•ì¸í–ˆì–´ìš”ğŸ’¡")

  st.success('''
  ğŸ“Œ ë²”ì£„ ë¹ˆë„ìˆ˜

  ğŸ“Œ (ë²”ì£„ ìœ í˜•ì— ë”°ë¼)ê³¼ê²©ì„±

  ğŸ“Œ (ë²”ì£„ ì¥ì†Œ)ê³µê°œì„±
             ''')



  # section2-1 : íˆíŠ¸ë§µ
  st.subheader("ì›”ë³„ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜")

  df1 = pd.DataFrame(fbi, columns=['DATA_YEAR', 'INCIDENT_DATE', 'OFFENSE_NAME', 'BIAS_DESC', 'LOCATION_NAME']) 
  df1 = df1[df1['BIAS_DESC'].str.contains('Anti-Asian', na = False)]     ## Anti-Asian
  df1 = df1[(df1['DATA_YEAR'] >= 2015)]      ## ì—°ë„ë³„ë¡œ ë³´ê¸° ìœ„í•´ 2016(íŠ¸ëŸ¼í”„ ë‹¹ì„  ì—°ë„ë¶€í„°: ì „í›„ë¹„êµ ëŠë‚Œ)

  df1['INCIDENT_DATE'] = pd.to_datetime(df1['INCIDENT_DATE'])

  #ì—°ë„-ë‹¬ ì»¬ëŸ¬ë§µ
  #ê° ì—°ë„ ê¸°ì¤€ìœ¼ë¡œ, ë‹¬ë³„ë¡œ ë²”ì£„ ê±´ìˆ˜ ì¹´ìš´íŠ¸í•´ì„œ ì €ì¥. ì´í›„ ì»¬ëŸ¬ë§µ ê·¸ë¦¬ê¸°
  df1['INCIDENT_DATE'] = pd.to_datetime(df1['INCIDENT_DATE'])

  @st.cache
  def count_monthly_crime(year_num):
      cases = []
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-01-01', f'{year_num}-01-31')])) #1ì›” - ìˆœì„œë‘ ë‚ ì§œ ë§ì¶”ë ¤ê³  ì¼ì¼íˆ í–ˆìŒ
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-02-01', f'{year_num}-02-28')])) #2ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-03-01', f'{year_num}-03-31')])) #3ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-04-01', f'{year_num}-04-30')])) #4ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-05-01', f'{year_num}-05-31')])) #5ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-06-01', f'{year_num}-06-30')])) #6ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-07-01', f'{year_num}-07-31')])) #7ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-08-01', f'{year_num}-08-30')])) #8ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-09-01', f'{year_num}-09-30')])) #9ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-10-01', f'{year_num}-10-31')])) #10ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-11-01', f'{year_num}-11-30')])) #11ì›”
      cases.append(len(df1[df1['INCIDENT_DATE'].between(f'{year_num}-12-01', f'{year_num}-12-31')])) #12ì›”
      return cases

  monthly_crime = [count_monthly_crime(2015), count_monthly_crime(2016), count_monthly_crime(2017), count_monthly_crime(2018), count_monthly_crime(2019), count_monthly_crime(2020)]

  month_name = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
  year_month_colormap = px.imshow(monthly_crime,
                  labels=dict(x="Months", y="Year", color="Cases", width=500, height=700), 
                  x = month_name,
                  y = ['2015', '2016', '2017', '2018', '2019', '2020'],
                  color_continuous_scale='Reds',
                  width = 800, height = 600)


  st.markdown("##### Asian Hate Crimes Cases (2015-2020)")
  st.plotly_chart(year_month_colormap, use_container_width = True)


  st.info('''
  * 2020ë…„ 3ì›”, ì €ê²Œ ë­ì•¼?: 2016ë…„ ëŒ€ì„ ì´ ìˆì—ˆë˜ 11ì›” ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ê°€ ì†Œí­ ì¦ê°€í•œ ì–‘ìƒì„ ë³´ì´ë©°, ì´í›„ ê°„í—ì ìœ¼ë¡œ ë°œìƒ ë¹ˆë„ê°€ ë†’ì•„ì§€ë˜ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ëŠ” 2020ë…„ ì½”ë¡œë‚˜19ê°€ ì°½ê¶í•˜ë˜ ì‹œê¸° ì •ì ì„ ì°ì—ˆì–´ìš”.
  ë¯¸êµ­ì— ì½”ë¡œë‚˜19ê°€ ë§‰ ìƒë¥™í•´ ê¸°ìŠ¹ì„ ë¶€ë¦¬ë˜ 3ì›”ê³¼ 4ì›”ì˜ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ëŠ” ê°ê° 52ê±´ìœ¼ë¡œ,
  ì´ì „ ìµœë‹¤ë°œìƒ ì›”ì¸ 2019ë…„ 12ì›”ì˜ 22ê±´ë³´ë‹¤ë„ 2.5ë°°ê°€ëŸ‰ ë†’ì€ ìˆ˜ì¹˜ì—ìš”!
  ê°™ì€ í•´ 10ì›”ê¹Œì§€ ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ëŠ” ë§¤ì›” 20ê±´ ì´ìƒìœ¼ë¡œ ìœ ë¡€ì—†ëŠ” ë°œìƒ í˜„í™©ì„ ë³´ì˜€ìŠµë‹ˆë‹¤ğŸš¨ 
          ''')

  st.markdown('''
              #
  #
              ''')



  # section2-2 : ë²”ì£„ì˜ ê³¼ê²©ì„±: ë¼ì¸, ë§‰ëŒ€
  st.subheader("í˜ì˜¤ ë²”ì£„ì˜ ê³¼ê²©ì„±, ì½”ë¡œë‚˜19 ì „í›„ë¥¼ ë³¼ê¹Œ?")

  st.success('''
  ê³¼ê²©ì„±ì€ ì‹ ì²´ì— ì§ì ‘ì ìœ¼ë¡œ ê°€í•´ì§€ëŠ” ìœ„í•´ ì •ë„ë¥¼ ë”°ì ¸, ë²”ì£„ ì¢…ë¥˜ì˜ ìœ„í•´ì„±ì´ ë†’ì„ìˆ˜ë¡ 4ì— ê°€ê¹ê²Œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. ë¯¸êµ­ ë³´í†µë²• ê¸°ì¤€ ê²½ë²”ì£„ì™€ ì¤‘ë²”ì£„ ë¶„ë¥˜ë¥¼ ì°¸ê³ í–ˆì„ ë•Œ, ëŒ€ì²´ë¡œ 1 ~ 2ì— í•´ë‹¹í•˜ëŠ” ë²”ì£„ëŠ” ê²½ë²”ì£„, 3 ~ 4ì— í•´ë‹¹í•˜ëŠ” ë²”ì£„ëŠ” ì¤‘ë²”ì£„ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.

  * 1 = í˜‘ë°•(intimidation), ë¬¸ì„œ ìœ„ì¡°(counterfeiting/forgery), ì•½ë¬¼ ì†Œì§€ ë° í•™êµì— ë“¤ê³  ê°(Drug violations), ë¬´ê¸° ì†Œì§€ ë° í•™êµì— ë“¤ê³  ê°(Weapon Law Violation)\n
  * 2 = ì ˆë„(theft), ì¬ë¬¼ì†ê´´(destruction/damage/vandalism of property), ê¸°íƒ€ ì ˆë„(all other larceny)\n
  * 3 = í­í–‰(assault), ê°•ë„(robbery), ì£¼ê±°ì¹¨ì…ê°•ë„(burglary/breaking & entering), ë°©í™”(arson)\n
  * 4 = ê°•ê°„(rape), ìœ ê´´(Kidnapping), ì‚´ì¸Â·ê³¼ì‹¤ì¹˜ì‚¬Â·ëª¨ì‚´(murder and nonnegligent manslaughter)\n
             ''')

  df1 = pd.DataFrame(fbi, columns=['DATA_YEAR', 'INCIDENT_DATE', 'OFFENSE_NAME', 'BIAS_DESC', 'LOCATION_NAME']) #í˜œì •ì´ê°€ ì“´ ë°ì´í„°í”„ë ˆì„ ë³€ìˆ˜ëª… ì•ˆê²¹ì¹˜ê²Œ df1ìœ¼ë¡œ.
  df1 = df1[df1['BIAS_DESC'].str.contains('Anti-Asian', na = False)]     ## Anti-Asian
  df1 = df1[(df1['DATA_YEAR'] >= 2019)]      ## 2019, 2020

  # crime type table
  offense_type_tab = pd.crosstab(df1.DATA_YEAR, df1.OFFENSE_NAME)
  # offense_type_tab

  # crime type cleaning
  df1.loc[(df1['OFFENSE_NAME'].str.startswith('Aggravated Assault')), 'OFFENSE_NAME'] = 'Aggravated Assault'
  df1.loc[(df1['OFFENSE_NAME'].str.startswith('Destruction/Damage/Vandalism of Property')), 'OFFENSE_NAME'] = 'Destruction/Damage/Vandalism of Property'
  df1.loc[(df1['OFFENSE_NAME'].str.startswith('Intimidation')), 'OFFENSE_NAME'] = 'Intimidation'
  df1.loc[(df1['OFFENSE_NAME'].str.contains('Drug')), 'OFFENSE_NAME'] = 'Drug Violations'
  df1.loc[(df1['OFFENSE_NAME'].str.contains('Theft')), 'OFFENSE_NAME'] = 'Theft'

  # crime type cleaning (2nd)
  df1.loc[df1['OFFENSE_NAME'] == 'Intimidation', 'OFFENSE_NAME'] = 1
  df1.loc[df1['OFFENSE_NAME'] == 'Counterfeiting/Forgery', 'OFFENSE_NAME'] = 1
  df1.loc[df1['OFFENSE_NAME'] == 'Drug Violations', 'OFFENSE_NAME'] = 1
  df1.loc[df1['OFFENSE_NAME'] == 'Weapon Law Violations', 'OFFENSE_NAME'] = 1

  df1.loc[df1['OFFENSE_NAME'] == 'All Other Larceny', 'OFFENSE_NAME'] = 2
  df1.loc[df1['OFFENSE_NAME'] == 'Theft', 'OFFENSE_NAME'] = 2
  df1.loc[df1['OFFENSE_NAME'] == 'Destruction/Damage/Vandalism of Property', 'OFFENSE_NAME'] = 2

  #ë°©í™”, ê°•ë„, ì£¼ê±°ì¹¨ì…ê°•ë„ ëª¨ë‘ 2ì—ì„œ 3ìœ¼ë¡œ ì˜®ê¹€
  df1.loc[df1['OFFENSE_NAME'] == 'Simple Assault', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Aggravated Assault', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Robbery', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Burglary/Breaking & Entering', 'OFFENSE_NAME'] = 3
  df1.loc[df1['OFFENSE_NAME'] == 'Arson', 'OFFENSE_NAME'] = 3

  df1.loc[df1['OFFENSE_NAME'] == 'Rape', 'OFFENSE_NAME'] = 4
  df1.loc[df1['OFFENSE_NAME'] == 'Murder and Nonnegligent Manslaughter', 'OFFENSE_NAME'] = 4

  df1.loc[df1['OFFENSE_NAME'] == 'Not Specified', 'OFFENSE_NAME'] = 5
  df1.loc[df1['OFFENSE_NAME'] == 'Hacking/Computer Invasion', 'OFFENSE_NAME'] = 5

  # crime type table (numeric order)
  offense_type_tab_c = pd.crosstab(df1.DATA_YEAR, df1.OFFENSE_NAME)

  # Line and Bar plot for crime type
  offense_type_line = pd.crosstab(df1.OFFENSE_NAME, columns= df1.DATA_YEAR)
  offense_type_bar = pd.crosstab(df1.OFFENSE_NAME, columns= df1.DATA_YEAR, normalize=True)
  offense_type_line_plt = px.line(offense_type_line, title = "Graph by type of crimes", markers=True, )
  offense_type_line_plt.update_layout(xaxis = dict({"title" : "Crime Type"}), yaxis = dict({"title" : "Counted Cases"}))
  offense_type_bar_plt = px.bar(offense_type_bar, title = " ", barmode = "group")
  offense_type_bar_plt.update_layout(xaxis = dict({"title" : "Crime Type"}), yaxis = dict({"title" : "Counted Cases"}))

  col1, col2 = st.columns(2)

  with col1:
      st.plotly_chart(offense_type_line_plt, use_container_width = True)

  with col2:
      st.plotly_chart(offense_type_bar_plt, use_container_width = True)

  st.info('''
  * í˜ì˜¤ ë²”ì£„, â€˜ë§ì´â€™ë§Œ ì¼ì–´ë‚œ ê²Œ ì•„ë‹ˆë‹¤: ë²”ì£„ì˜ ê³¼ê²©ì„±ë„ ëŒ€í­ ì¦ê°€í–ˆì–´ìš”. ì‚´ì¸ê³¼ ê°™ì€ ê³¼ê²©ì„± 4 ì •ë„ì˜ ì¤‘ë²”ì£„ë¥¼ ì œì™¸í•˜ê³ , 2019ë…„ ëŒ€ë¹„ 2020ë…„ ì•„ì‹œì•„ì¸ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ê³¼ê²©ì„± 1~3ì˜ í˜ì˜¤ ë²”ì£„ ë¹„ì¤‘ì´ ë†’ì•„ì§„ ê²ƒ ë³´ì´ì‹œë‚˜ìš”?
  * ê²½ë²”ì£„, ì¤‘ë²”ì£„ ëª¨ë‘ ì¦ê°€: 1~2ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²½ë²”ì£„ëŠ” ë¬¼ë¡ , í­í–‰ê³¼ ê°•ë„ ë“±ì˜ ì¤‘ë²”ì£„ë„ ì•„ì‹œì•„ì¸ì„ ëŒ€ìƒìœ¼ë¡œ ì ì§€ ì•Šê²Œ í–‰í•´ì¡Œë„¤ìš”.
          ''')

  st.markdown('''
              #
  #
              ''')


  # section2-3 : ë²”ì£„ì˜ ê³µê°œì„±: ë¼ì¸, ë§‰ëŒ€
  st.subheader("í˜ì˜¤ ë²”ì£„ì˜ ê³µê°œì„±, ì½”ë¡œë‚˜19 ì „í›„ë¥¼ ë³¼ê¹Œ?")

  st.success('''
  2019ë…„ ~ 2020ë…„: ë²”ì£„ ì¥ì†Œì˜ ê³µê°œì„± ë³€í™”\në²”ì£„ ì¥ì†Œì˜ ê³µê°œì„±ì€ ì¥ì†Œì˜ ê°œë°©ì„±ê³¼ ê³µê³µì„±, ìœ ë™ ì¸êµ¬ë¥¼ ê³ ë ¤í•´ 1~5ì˜ ìˆ˜ì¹˜ë¡œ ë¶„ë¥˜í–ˆìœ¼ë©°, ìˆ«ìê°€ ì»¤ì§ˆìˆ˜ë¡ ê³µê°œì„±ì´ ë†’ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê³µê°œì„±ì´ 1, 2ì´ë©´ íì‡„ì ì¸ ì¥ì†Œ, ê³µê°œì„±ì´ 3ì´ë©´ ê³µê°„ ê°œë°©ì„±ì€ ë†’ìœ¼ë‚˜ ìœ ë™ì¸êµ¬ëŠ” ì ì€ ì¥ì†Œ, ê³µê°œì„±ì´ 4,5ì´ë©´ ìœ ë™ ì¸êµ¬ì™€ ê³µê³µì„±ì´ ëª¨ë‘ ë†’ì€ ì¥ì†Œì…ë‹ˆë‹¤. 

  *6ì€ ê³µê°œì„±ì„ ì„ì˜ë¡œ ì¸¡ì •í•˜ê¸° ì–´ë ¤ìš´ ê¸°íƒ€ ë²”ì£„ ì¥ì†Œì…ë‹ˆë‹¤.

  1 = ì§‘(Residence/Home), ìˆ™ë°•ì—…ì†Œ(Hotel/Motel/Etc.)\n
  2 = ì „ë¬¸ìƒì (Specialty store), ì£¼ë¥˜ íŒë§¤ì (Liquor Store), ì°¨ ë”œëŸ¬ìƒµ(Auto Dealership New/Used)\n
  3 = ê³µì¥ ë¶€ì§€(Industrial Site), ë“¤íŒÂ·ìˆ²(Field/Woods), ê°•ê°€Â·ë°”ë‹·ê°€(Lake/Waterway/Beach), ì£¼ì°¨ì¥Â·ì°¨ê³ (Parking/Drop Lot/Garage), ì£¼ìœ ì†ŒÂ·ì„œë¹„ìŠ¤ì„¼í„°(Service/Gas Station)\n
  4 = ìˆ ì§‘Â·ë‚˜ì´íŠ¸í´ëŸ½(Bar/Nightclub), ì‹ë‹¹(Restaurant), ê³µì›Â·ë†€ì´í„°(Park/Playground), ë„ë¡œÂ·ë³´ë„(Highway/Road/Alley/Street/Sidewalk), íœ´ê²Œì†Œ(rest area), convenience store(í¸ì˜ì ), ë°±í™”ì Â·í• ì¸íŒë§¤ì (Department/Discount Store), ì‡¼í•‘ëª°(Shopping Mall), ì‹ë£Œí’ˆì Â·ìŠˆí¼ë§ˆì¼“(Grocery/Supermarket), êµí†µ ì‹œì„¤(Air/Bus/Train Terminal), ìƒì—…ìš© ê±´ë¬¼(Commercial/Office Building)\n
  5 = ì´ˆÂ·ì¤‘ë“±Â·ëŒ€í•™êµ(School-College/Elementary/Secondary), ì£¼ë¯¼ìì¹˜ì„¼í„°(Community Center), í™ˆë¦¬ìŠ¤ ì‰¼í„°(Shelter-Mission/Homeless), ì€í–‰(Bank/Savings and Loan), ì¢…êµ ì‹œì„¤(Church/Synagogue/Temple/Mosque), ì •ë¶€Â·ê³µê³µê¸°ê´€ ê±´ë¬¼(Church/Synagogue/Temple/Mosque), ì˜ë£Œê¸°ê´€(Drug Store/Doctor's Office/Hospital)\n
  6 = ì•Œë ¤ì§€ì§€ ì•ŠìŒ(Other/Unknown), ì˜¨ë¼ì¸ ê³µê°„(Cyber space)
             ''')

  # crime place cleaning
  df1.loc[df1['LOCATION_NAME'] == 'Residence/Home', 'LOCATION_NAME'] = 1
  df1.loc[df1['LOCATION_NAME'] == 'Hotel/Motel/Etc.', 'LOCATION_NAME'] = 1

  df1.loc[df1['LOCATION_NAME'] == 'Auto Dealership New/Used', 'LOCATION_NAME'] = 2
  df1.loc[df1['LOCATION_NAME'] == 'Specialty Store', 'LOCATION_NAME'] = 2
  df1.loc[df1['LOCATION_NAME'] == 'Liquor Store', 'LOCATION_NAME'] = 2

  df1.loc[df1['LOCATION_NAME'] == 'Field/Woods', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Lake/Waterway/Beach', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Parking/Drop Lot/Garage', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Service/Gas Station', 'LOCATION_NAME'] = 3
  df1.loc[df1['LOCATION_NAME'] == 'Industrial Site', 'LOCATION_NAME'] = 3

  df1.loc[df1['LOCATION_NAME'] == 'Convenience Store', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Department/Discount Store', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Shopping Mall', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Grocery/Supermarket', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Air/Bus/Train Terminal', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Commercial/Office Building', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Park/Playground', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Highway/Road/Alley/Street/Sidewalk', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Rest Area', 'LOCATION_NAME'] = 4.
  df1.loc[df1['LOCATION_NAME'] == 'Bar/Nightclub', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Restaurant', 'LOCATION_NAME'] = 4
  df1.loc[df1['LOCATION_NAME'] == 'Highway/Road/Alley/Street/Sidewalk;Residence/Home', 'LOCATION_NAME'] = 4


  
  df1.loc[df1['LOCATION_NAME'] == 'School-College/University', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'School-Elementary/Secondary', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'School/College', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Community Center', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Shelter-Mission/Homeless', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Bank/Savings and Loan', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Church/Synagogue/Temple/Mosque', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == 'Government/Public Building', 'LOCATION_NAME'] = 5
  df1.loc[df1['LOCATION_NAME'] == "Drug Store/Doctor's Office/Hospital", 'LOCATION_NAME'] = 5


  df1.loc[df1['LOCATION_NAME'] == 'Cyberspace', 'LOCATION_NAME'] = 6
  df1.loc[df1['LOCATION_NAME'] == 'Other/Unknown', 'LOCATION_NAME'] = 6

  # Line and Bar plot for publicity of place
  offense_place_tab_c = pd.crosstab(df1.LOCATION_NAME, df1.DATA_YEAR)
  offense_place_line = pd.crosstab(df1.LOCATION_NAME, columns = df1.DATA_YEAR)
  offense_place_bar = pd.crosstab(df1.LOCATION_NAME, columns = df1.DATA_YEAR)

  offense_place_line_plt = px.line(offense_place_line, title = "Graph by type of places")
  offense_place_bar_plt = px.bar(offense_place_bar, title = " ", barmode = "group")

  offense_place_line_plt.update_layout(xaxis = dict({"title" : "Crime Location"}), yaxis = dict({"title" : "Counted Cases"}))
  offense_place_bar_plt.update_layout(xaxis = dict({"title" : "Crime Location"}), yaxis = dict({"title" : "Counted Cases"}))

  col1, col2 = st.columns(2)

  with col1:
      st.plotly_chart(offense_place_line_plt, use_container_width = True)
  with col2:
      st.plotly_chart(offense_place_bar_plt, use_container_width = True)

  st.info('''
  * ì¼ìƒì  ê³µê°„ì— ìŠ¤ë©°ë“  í˜ì˜¤ ë²”ì£„: ìœ ë™ ì¸êµ¬ê°€ ë§ê³  ê°œë°©ì„±ì´ ë†’ì€ ê³µê°œì„± 4ì˜ ì¥ì†Œì—ì„œ ë°œìƒí•œ í˜ì˜¤ ë²”ì£„ ë¹ˆë„ìˆ˜ê°€ ì „ë…„ë„ ëŒ€ë¹„ 2020ë…„ ë‘ ë°° ê°€ëŸ‰ ì¦ê°€í–ˆì–´ìš”. ê³µê°œì„± 1~3ì˜ ì¥ì†Œì—ì„œ ë°œìƒí•œ ë²”ì£„ë„ ì¦ê°€í–ˆì§€ë§Œ, ê³µê°œì„± 4ê°€ ìœ ë… ì¦ê°€í–ˆë„¤ìš”. ë²”ì£„ ì¥ì†Œì˜ ì¦ê°€í•œ ê³µê°œì„±ì€ ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„ê°€ ë”ìš± ê³µê³µì—°í•˜ê²Œ ë°œìƒí•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤˜ìš”.
          ''')


  st.markdown("""
  ##### âœ‹ì ê¹! ì—¬ê¸°ê¹Œì§€ ì •ë¦¬ âœ‹
  * ë¯¸êµ­ ì „ì—­ ê¸°ì¤€ìœ¼ë¡œ ë´¤ì„ ë•Œ, ì½”ë¡œë‚˜19ê°€ ë°œìƒí•œ 2020ë…„ ì´ˆë¥¼ ê¸°ì ìœ¼ë¡œ ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ ë²”ì£„ ê±´ìˆ˜ê°€ ê¸‰ì¦í–ˆì–´ìš”. ê°•ë„, í­í–‰ ë“± ë²”ì£„ì˜ ê³¼ê²©ì„±ë„ ì¦ê°€í–ˆê³ , ë²”ì£„ ì¥ì†Œì˜ ê³µê³µì„±ê³¼ ê°œë°©ì„±, ìœ ë™ì¸êµ¬ë¥¼ ì²™ë„ë¡œ ë§¤ê¸´ ê³µê°œì„±ë„ í•¨ê»˜ ì¦ê°€í–ˆê³ ìš”. 
  * ìš”ì»¨ëŒ€ ì½”ë¡œë‚˜19ì˜ ë°œìƒê³¼ ë¯¸êµ­ ë‚´ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì˜ ì‹¬ê°ì„±ì€, ì¼ì¢…ì˜ ìƒê´€ê´€ê³„ë¥¼ ì§€ë‹ˆê³  ìˆìŒì„ ì¶”ë¡ í•  ìˆ˜ ìˆì–´ìš”.
  """)

elif add_radio == "ğŸ”ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, ì§€ì—­ìœ¼ë¡œ ì¢í˜€ ë³´ì!":
    # section 3: ì£¼ë³„ ë¹„êµ

    st.markdown('''
    ## ğŸ”ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„, ì§€ì—­ìœ¼ë¡œ ì¢í˜€ ë³´ì!
                ''')



    # section 3-1: ì•„ì‹œì•„ì¸ ì¸êµ¬

    image = Image.open('population_map.png')
    st.image(image, caption = "Population of Asian in US")

    st.markdown('''
    #
                ''')



    # section 3-2: ì‚¬ë§ììˆ˜

    #íŒŒì¼ ì„í¬íŠ¸ 
    covid_state = pd.read_csv("us_county_covid_2020.csv") #2020ë…„ 12ì›” 31ì¼ ê¸°ì¤€, ë¯¸êµ­ ê° ì£¼ countyë³„ ëˆ„ì  í™•ì§„ ìˆ˜ë¥¼ ë‹´ì€ íŒŒì¼.

    #ì£¼ë³„ ì¸êµ¬ 10ë§Œëª… ë‹¹ ì½”ë¡œë‚˜19 í™•ì§„ì ìˆ˜ í‘œ ê·¸ë¦¬ê¸°
    covid_state_df = pd.DataFrame(covid_state)

    @st.cache #ìºì‹œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    #ì£¼ë³„ ëˆ„ì  ì‚¬ë§ ê±´ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
    def state_deaths(state_name):
        state = covid_state_df.loc[covid_state_df['state'] == state_name]
        return state['deaths'].sum()

    state_name_list = list(covid_state_df['state'].unique())

    deaths_list = []
    for item in state_name_list:
        deaths_list.append(int(state_deaths(item)))

    #deaths_list

    state_death = {'State':state_name_list, 'Deaths':deaths_list}
    state_death_df = pd.DataFrame(state_death)

    #10ë§Œ ëª…ë‹¹: (ì „ì²´ ê±´ìˆ˜ / 2020 ê¸°ì¤€ í•´ë‹¹ ì£¼ ì¸êµ¬ìˆ˜) * 100,000 - í•´ë‹¹ ì£¼ ì¸êµ¬ìˆ˜ëŠ” us census.gov ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜¨ íŒŒì¼, 2020 7ì›” ê¸°ì¤€
    us_population = pd.read_csv("us_population_2020.csv")
    us_population['2020'] = us_population['2020'].apply(lambda x: int(x.replace(',', '')))
    us_death_population = pd.merge(state_death_df, us_population)

    #1ì²œ ëª…ë‹¹ ì‚¬ë§ì ìˆ˜ : (ì „ì²´ ê±´ìˆ˜ / 2020 ê¸°ì¤€ í•´ë‹¹ ì£¼ ì¸êµ¬ìˆ˜) * 1000
    us_death_population['deaths_per_1k'] = us_death_population.apply(lambda x: ((x['Deaths'] / x['2020']) * 1000), axis=1)
    us_death_population_final = us_death_population[['State', 'deaths_per_1k']]

    from urllib.request import urlopen
    import json
    with urlopen('https://raw.githubusercontent.com/ChoiDayeun/datajournalism_streamlit/main/us-states_json_edit.json') as response:
        states = json.load(response)

    #ì§€ë„ ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ ì‹œê°í™”.
    fig_death_population = px.choropleth(us_death_population_final, geojson= states, locations='State', 
                        color = 'deaths_per_1k',
                        color_continuous_scale="Reds",
                        range_color=(0, us_death_population_final.deaths_per_1k.max()),
                        featureidkey='properties.State',
                        scope="usa",
                        labels={'deaths_per_1k':'deaths per 1k'},
                        title = 'US COVID-19 Deaths per 1k by States'
                        )
    fig_death_population.update_layout(margin={"r":0,"t":60,"l":0,"b":0})
    #fig_death_population.show()

    st.plotly_chart(fig_death_population, use_container_width = True)




    # section 3-3 : 2019/2020 Asian hate crime
    #ì£¼ë³„ ì•„ì‹œì•„ì¸ í˜ì˜¤ë²”ì£„ ê±´ìˆ˜ í‘œ ê·¸ë¦¬ê¸°: 2019, 2020
    fbi_2019 = fbi.loc[fbi['DATA_YEAR'] == 2019]
    fbi_2019 = fbi_2019[fbi_2019['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    fbi_state_2019 = fbi_2019[['STATE_NAME']]

    #ê° ì£¼ë³„ ë²”ì£„ ì´ ê±´ìˆ˜ ì„¸ëŠ” í•¨ìˆ˜
    @st.cache #ìºì‹œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    def state_crimes(state_name):
        state = fbi_state_2019.loc[fbi_state_2019['STATE_NAME'] == state_name]
        return len(state)

    #state_crimes('New York')

    crime_list_2019 = []
    for item in state_name_list:
        #print(item)
        crime_list_2019.append(int(state_crimes(item)))

    state_crime_2019 = {'State':state_name_list, 'Crimes':crime_list_2019}
    state_crime_df_2019 = pd.DataFrame(state_crime_2019)
    #state_crime_df_2019

    ###############2020ë…„##################
    fbi_2020 = fbi.loc[fbi['DATA_YEAR'] == 2020]
    fbi_2020 = fbi_2020[fbi_2020['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    fbi_state_2020 = fbi_2020[['STATE_NAME']]

    #ê° ì£¼ë³„ ë²”ì£„ ì´ ê±´ìˆ˜ ì„¸ëŠ” í•¨ìˆ˜
    @st.cache #ìºì‹œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
    def state_crimes(state_name):
        state = fbi_state_2020.loc[fbi_state_2020['STATE_NAME'] == state_name]
        return len(state)

    #state_crimes('New York')

    crime_list_2020 = []
    for item in state_name_list:
        #print(item)
        crime_list_2020.append(int(state_crimes(item)))

    state_crime_2020 = {'State':state_name_list, 'Crimes':crime_list_2020}
    state_crime_df_2020 = pd.DataFrame(state_crime_2020)
    #state_crime_df_2019

    ######í‘œ######

    fig_crime_2019 = px.choropleth(state_crime_df_2019, geojson= states, locations='State', 
                        color = 'Crimes',
                        color_continuous_scale="Blues",
                        range_color=(0, state_crime_df_2020.Crimes.max()),
                        featureidkey='properties.State',
                        scope="usa",
                        labels={'case':'Crimes'},
                        title = 'Asian Hate Crime Cases per State 2019', 
                        )
    fig_crime_2019.update_layout(margin={"r":0,"t":60,"l":0,"b":0})
    #fig_crime_2019.show()


    fig_crime_2020 = px.choropleth(state_crime_df_2020, geojson= states, locations='State', 
                        color = 'Crimes',
                        color_continuous_scale="Blues",
                        range_color=(0, state_crime_df_2020.Crimes.max()),
                        featureidkey='properties.State',
                        scope="usa",
                        labels={'case':'Crimes'},
                        title = 'Asian Hate Crime Cases per State 2020', 
                        )
    fig_crime_2020.update_layout(margin={"r":0,"t":60,"l":0,"b":0})


    st.markdown('''
    #
                ''')
    select_yr = st.selectbox('í™•ì¸í•  í•´ë¥¼ ì„ íƒí•˜ì„¸ìš”', ['2019', '2020'])
    if select_yr == '2019':
        st.plotly_chart(fig_crime_2019)
    elif select_yr == '2020':
        st.plotly_chart(fig_crime_2020)

    st.info('''
    * ì½”ë¡œë‚˜19 í”¼í•´ ì‹¬í–ˆë˜ ì£¼, í˜ì˜¤ ë²”ì£„ë„ ë§ì•˜ë‹¤: ì½”ë¡œë‚˜19 ì‚¬ë§ììˆ˜ì™€ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ë°œìƒ ìˆ˜ë¥¼ ì£¼ë³„ë¡œ ê·¸ë¦° ì§€ë„ë‘, ì•„ì‹œì•„ì¸ ì¸êµ¬ ë¶„í¬ë„ë¥¼ ë³´ì—¬ì¤„ê²Œìš”. ì‚¬ë§ìê°€ ë§ì€ ì£¼ì—ì„œ í˜ì˜¤ ë²”ì£„ ìˆ˜ë„ ë§ì´ ë°œìƒí•˜ëŠ” ê²½í–¥ì´ ë³´ì´ë„¤ìš”.
    ''')

    ####ì£¼ë³„ ì •ë¦¬ ë‹¤ì‹œ: 10ê°œ###


    #1000ëª…ë‹¹ ì‚¬ë§ììˆ˜ë³„ë¡œ ì •ë ¬: ìƒìœ„ 10ê°œ, í•˜ìœ„ 10ê°œ ì£¼ ì¶”ì¶œ
    #ìƒìœ„ 10ê°œ, í•˜ìœ„ 10ê°œ
    death_top10_df = us_death_population_final.sort_values('deaths_per_1k', ascending = False)[:10]
    death_bottom10_df = us_death_population_final.sort_values('deaths_per_1k')[:10]

    #í•´ë‹¹ ì£¼ ì´ë¦„ë“¤ ì¶”ì¶œ
    death_top10_names = []
    death_bottom10_names = []
    for item in death_top10_df['State']:
        death_top10_names.append(item)


    for item in death_bottom10_df['State']:
        death_bottom10_names.append(item)


    #################ì‚¬ë§ììˆ˜ ê¸°ì¤€ ##################

    df_new2 = pd.DataFrame(fbi, columns=['DATA_YEAR', 'STATE_NAME', 'OFFENSE_NAME', 'BIAS_DESC', 'LOCATION_NAME'])
    df_new2 = df_new2[(df_new2['DATA_YEAR'] >= 2019)]

    df_new2.loc[(df_new2['OFFENSE_NAME'].str.startswith('Aggravated Assault')), 'OFFENSE_NAME'] = 'Aggravated Assault'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.startswith('Murder and Nonnegligent Manslaughter')), 'OFFENSE_NAME'] = 'Murder and Nonnegligent Manslaughter'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Destruction/Damage/Vandalism of Property')), 'OFFENSE_NAME'] = 'Destruction/Damage/Vandalism of Property'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Intimidation')), 'OFFENSE_NAME'] = 'Intimidation'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Drug')), 'OFFENSE_NAME'] = 'Drug Violations'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Theft')), 'OFFENSE_NAME'] = 'Theft'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Robbery')), 'OFFENSE_NAME'] = 'Robbery'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Burglary')), 'OFFENSE_NAME'] = 'Burglary'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Fraud')), 'OFFENSE_NAME'] = 'Fraud'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Rape')), 'OFFENSE_NAME'] = 'Rape'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Prostitution')), 'OFFENSE_NAME'] = 'Prostitution'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Arson')), 'OFFENSE_NAME'] = 'Arson'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.startswith('Kidnapping')), 'OFFENSE_NAME'] = 'Kidnapping'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Extortion')), 'OFFENSE_NAME'] = 'Extortion'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Shoplifting')), 'OFFENSE_NAME'] = 'Shoplifting'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Purse-snatching')), 'OFFENSE_NAME'] = 'Shoplifting'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Pocket-picking')), 'OFFENSE_NAME'] = 'Shoplifting' #ì•½ê°„ ì¢€ë„ë‘‘ ëŠë‚Œì´ë©´ ë‹¤ shoplifting 
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Fondling')), 'OFFENSE_NAME'] = 'Fondling'
    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('Simple Assault')), 'OFFENSE_NAME'] = 'Simple Assault'


    df_new2.loc[(df_new2['OFFENSE_NAME'].str.contains('All Other Larceny')), 'OFFENSE_NAME'] = 'All Other Larceny' #ë‹¤ ì •ë¦¬í•˜ê³ ë„ ë‚¨ìœ¼ë©´ ê¸°íƒ€ë¡œ ë¹¼ê¸°.

    # crime type cleaning (2nd)
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Intimidation', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Counterfeiting/Forgery', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Drug Violations', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Weapon Law Violations', 'OFFENSE_NAME'] = 1 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Embezzlement', 'OFFENSE_NAME'] = 1 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Sodomy', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Extortion', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Fondling', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Pornography/Obscene Material', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Shoplifting', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Impersonation', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Fraud', 'OFFENSE_NAME'] = 1 #ì‚¬ê¸°ê¹Œì§€
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'False Pretenses/Swindle/Confidence Game', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Stolen Property Offenses', 'OFFENSE_NAME'] = 1
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Animal Cruelty', 'OFFENSE_NAME'] = 1

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'All Other Larceny', 'OFFENSE_NAME'] = 2
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Theft', 'OFFENSE_NAME'] = 2 #ì—¬ê¸°ì„œë¶€í„°ëŠ” ì ˆë„ ë“±ë“±
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Destruction/Damage/Vandalism of Property', 'OFFENSE_NAME'] = 2
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Prostitution', 'OFFENSE_NAME'] = 2 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Human Trafficking, Commercial Sex Acts', 'OFFENSE_NAME'] = 2

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Arson', 'OFFENSE_NAME'] = 3 #ë°©í™”ëŠ” 3ìœ¼ë¡œ ë¹¼ëŠ” ê²ƒì€ ì–´ë–¨ì§€? 
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Robbery', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Burglary', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Simple Assault', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Aggravated Assault', 'OFFENSE_NAME'] = 3 #ê°€ì¤‘ í­í–‰
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Sexual Assault With An Object', 'OFFENSE_NAME'] = 3
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Negligent Manslaughter', 'OFFENSE_NAME'] = 3

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Kidnapping', 'OFFENSE_NAME'] = 4 #ìœ ê´´ 3? 4?
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Rape', 'OFFENSE_NAME'] = 4
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Murder and Nonnegligent Manslaughter', 'OFFENSE_NAME'] = 4

    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Not Specified', 'OFFENSE_NAME'] = 5
    df_new2.loc[df_new2['OFFENSE_NAME'] == 'Hacking/Computer Invasion', 'OFFENSE_NAME'] = 5 #1ë¡œ ë³´ë‚´ëŠ” ê²ƒì€ ì–´ë–¨ì§€? 


    # crime place cleaning 1st

    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Highway/Road/Alley/Street/Sidewalk')), 'LOCATION_NAME'] = 'Highway/Road/Alley/Street/Sidewalk'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Store')), 'LOCATION_NAME'] = 'Store'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Facility')), 'LOCATION_NAME'] = 'Facility'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('School-Elementary/Secondary')), 'LOCATION_NAME'] = 'School-Elementary/Secondary'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Auto Dealership New/Used')), 'LOCATION_NAME'] = 'Auto Dealership New/Used'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.startswith('Hotel/Motel/Etc')), 'LOCATION_NAME'] = 'Hotel/Motel/Etc'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Amusement Park')), 'LOCATION_NAME'] = 'Amusement Park' 
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('Commercial/Office Building')), 'LOCATION_NAME'] = 'Commercial/Office Building'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.contains('ATM Separate from Bank')), 'LOCATION_NAME'] = 'ATM Separate from Bank'
    df_new2.loc[(df_new2['LOCATION_NAME'].str.startswith('Grocery/Supermarket')), 'LOCATION_NAME'] = 'Grocery/Supermarket'  

    df_new2.loc[(df_new2['LOCATION_NAME'].str.startswith('Other/Unknown')), 'LOCATION_NAME'] = 'Other/Unknown' #ê¸°íƒ€ 

    # crime place cleaning 2nd
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Residence/Home', 'LOCATION_NAME'] = 1
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Hotel/Motel/Etc', 'LOCATION_NAME'] = 1


    df_new2.loc[df_new2['LOCATION_NAME'] == 'ATM Separate from Bank', 'LOCATION_NAME'] = 2 
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Auto Dealership New/Used', 'LOCATION_NAME'] = 2
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Abandoned/Condemned Structure', 'LOCATION_NAME'] = 2
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Military Installation', 'LOCATION_NAME'] = 2 #ì–˜ë„ 3ìœ¼ë¡œ ë¹¼ëŠ” ê²ƒì€ ì–´ë–¨ì§€?


    df_new2.loc[df_new2['LOCATION_NAME'] == 'Construction Site', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Industrial Site', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Field/Woods', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Camp/Campground', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Arena/Stadium/Fairgrounds/Coliseum', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Tribal Lands', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Service/Gas Station', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Lake/Waterway/Beach', 'LOCATION_NAME'] = 3
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Parking/Drop Lot/Garage', 'LOCATION_NAME'] = 3

    df_new2.loc[df_new2['LOCATION_NAME'] == 'Store', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Facility', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Shopping Mall', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Grocery/Supermarket', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Air/Bus/Train Terminal', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Dock/Wharf/Freight/Modal Terminal', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Commercial/Office Building', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Bar/Nightclub', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Restaurant', 'LOCATION_NAME'] = 4

    df_new2.loc[df_new2['LOCATION_NAME'] == 'School-College/University', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'School-Elementary/Secondary', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'School/College', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Community Center', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Shelter-Mission/Homeless', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Bank/Savings and Loan', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Church/Synagogue/Temple/Mosque', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Government/Public Building', 'LOCATION_NAME'] = 5
    df_new2.loc[df_new2['LOCATION_NAME'] == "Drug Store/Doctor's Office/Hospital", 'LOCATION_NAME'] = 5 


    df_new2.loc[df_new2['LOCATION_NAME'] == 'Amusement Park', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Park/Playground', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Highway/Road/Alley/Street/Sidewalk', 'LOCATION_NAME'] = 4
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Rest Area', 'LOCATION_NAME'] = 4


    df_new2.loc[df_new2['LOCATION_NAME'] == 'Cyberspace', 'LOCATION_NAME'] = 6
    df_new2.loc[df_new2['LOCATION_NAME'] == 'Other/Unknown', 'LOCATION_NAME'] = 6


    #death_top10_names,  death_bottom10_namesì— ìˆëŠ” ì£¼ë“¤ì˜ ê°’ì„ ë°”ê¾¼ í›„, dfì— í•´ë‹¹ ì»¬ëŸ¼ë“¤ë§Œ ë‚¨ê¹€: ìƒìœ„ 10ê°œ : TOP_10_COVID_deathS, BOTTOM_10_COVID_deathS
    for item in death_top10_names:
        df_new2.loc[df_new2['STATE_NAME'] == item, 'STATE_NAME'] = 'TOP_10_COVID_DEATHS'
    for item in death_bottom10_names:
        df_new2.loc[df_new2['STATE_NAME'] == item, 'STATE_NAME'] = 'BOTTOM_10_COVID_DEATHS'
    df_deaths_state = df_new2.loc[(df_new2['STATE_NAME'] == 'TOP_10_COVID_DEATHS') | (df_new2['STATE_NAME'] == 'BOTTOM_10_COVID_DEATHS')]


    ##ì•„ì‹œì•„ì¸ ëŒ€ìƒ í˜ì˜¤ë²”ì£„ë§Œ, ì‚¬ë§ììˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì¶œ
    df_state_asian = df_deaths_state[df_deaths_state['BIAS_DESC'].str.contains('Anti-Asian', na = False)] 
    offense_list_asian2 = list(df_state_asian['LOCATION_NAME'].unique())
    offense_list_asian2.sort()

    top10_asian_df = df_state_asian[df_state_asian['STATE_NAME'] == 'TOP_10_COVID_DEATHS']
    #ì—¬ê¸°ë¶€í„°: offense_name_top10 = list(top10_asian_df['OFFENSE_NAME'].unique())
    
    
    

    #from pandas import Series, DataFrame
    
    #ì‚¬ë§ììˆ˜ ê°€ì¥ ë§ì€ ìƒìœ„ 10ê°œ ì£¼ ê¸°ì¤€
    #ë²”ì£„ì˜ ê³¼ê²©ì„±
    
    raw_data = {'year': [2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2020],
                'offense_name': [0, 1, 2, 3, 4, 0, 1, 2, 3, 4],
                'offense_number': [0, 37, 7, 19, 2, 1, 60, 19, 37, 0]}

    offense_name2 = DataFrame(raw_data)
    #print(offense_name2)


    fig_off_asian = px.scatter(offense_name2, x="offense_number", y="offense_name",    color="year", color_continuous_scale='Bluered_r')
    # iterate on each region
    for i in offense_name2["offense_name"].unique():
        # filter by region
        df_sub = offense_name2[offense_name2["offense_name"] == i]

        fig_off_asian.add_shape(
            type="line",
            layer="below",
            # connect the two markers
            ## e.g., y0='Robredo', x0=43.53
            y0=df_sub.offense_name.values[0], x0=df_sub.offense_number.values[0],
            ## e.g., y1='Marcos', x1=26.60
            y1=df_sub.offense_name.values[1], x1=df_sub.offense_number.values[1], 
        )
    

    #ë²”ì£„ ì¥ì†Œì˜ ê³µê°œì„±
    raw_data2 = {'year': [2019, 2019, 2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020, 2020, 2020],
                'location_name': [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5],
                'location_number': [11, 9, 1, 5, 21, 18, 44, 22, 0, 4, 38, 9]}

    location_names = DataFrame(raw_data2)
    #print(location_names)

    #import plotly.express as px
    fig_loc_asian = px.scatter(location_names, x="location_number", y="location_name", color="year", color_continuous_scale='Bluered_r')
    # iterate on each region
    for i in location_names["location_name"].unique():
        # filter by region
        df_sub = location_names[location_names["location_name"] == i]

        fig_loc_asian.add_shape(
            type="line",
            layer="below",
            # connect the two markers
            ## e.g., y0='Robredo', x0=43.53
            y0=df_sub.location_name.values[0], x0=df_sub.location_number.values[0],
            ## e.g., y1='Marcos', x1=26.60
            y1=df_sub.location_name.values[1], x1=df_sub.location_number.values[1], 
        )
    #fig.show()
    
    raw_data_3 = {'year': [2019, 2019, 2019, 2020, 2020, 2020],
                'offense_name': [1, 2, 3, 1, 2, 3],
                'offense_number': [18, 5, 20, 19, 10, 18]}

    offense_name3 = DataFrame(raw_data_3)


    fig_off_asian_bottom = px.scatter(offense_name3, x="offense_number", y="offense_name",    color="year", color_continuous_scale='Bluered_r')
    # iterate on each region
    for i in offense_name3["offense_name"].unique():
        # filter by region
        df_sub = offense_name3[offense_name3["offense_name"] == i]

        fig_off_asian_bottom.add_shape(
            type="line",
            layer="below",
            y0=df_sub.offense_name.values[0], x0=df_sub.offense_number.values[0],
            ## e.g., y1='Marcos', x1=26.60
            y1=df_sub.offense_name.values[1], x1=df_sub.offense_number.values[1], 
        )


    raw_data4 = {'year': [2019, 2019, 2019, 2019, 2020, 2020, 2020, 2020],
                'location_name': [1, 3, 4, 5, 1, 3, 4, 5],
                'location_number': [7, 3, 23, 10, 13, 3, 27, 4]}

    location_names4 = DataFrame(raw_data4)

    fig_loc_asian_bottom = px.scatter(location_names4, x="location_number", y="location_name", color="year", color_continuous_scale='Bluered_r')
    # iterate on each region
    for i in location_names4["location_name"].unique():
        # filter by region
        df_sub = location_names4[location_names4["location_name"] == i]

        fig_loc_asian_bottom.add_shape(
            type="line",
            layer="below",
            # connect the two markers
            ## e.g., y0='Robredo', x0=43.53
            y0=df_sub.location_name.values[0], x0=df_sub.location_number.values[0],
            ## e.g., y1='Marcos', x1=26.60
            y1=df_sub.location_name.values[1], x1=df_sub.location_number.values[1], 
        )
    st.write("ì½”ë¡œë‚˜19 ì‚¬ë§ì ìƒìœ„ 10ê°œ ì£¼")
    st.write(fig_off_asian)
    st.write(fig_loc_asian)
    
    #ë²”ì£„ ê³¼ê²©ì„± ë¹„êµ
    st.info('''
    * ì¤‘ë²”ì£„, ìƒìœ„ 10ê°œì£¼ì—ì„œë§Œ ì¦ê°€: ê³¼ê²©ì„± 3, 4ì¸ ì¤‘ë²”ì£„ëŠ” ì‚¬ë§ì ìˆ˜ê°€ ë§ì•˜ë˜ ìƒìœ„ 10ê°œ ì£¼ì—ì„œëŠ” ì¦ê°€í•œ ë°˜ë©´ í•˜ìœ„ 10ê°œ ì£¼ì—ì„œëŠ” ê°ì†Œí–ˆì–´ìš”. í•˜ìœ„ 10ê°œì£¼ì—ì„œ ê³¼ê²©ì„± 4ì˜ ë²”ì£„ëŠ” ì•„ì˜ˆ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒë„ ì£¼ëª©í•´ì£¼ì„¸ìš”!
    * ê²½ë²”ì£„ë„ ë” ë†’ì€ ë¹„ìœ¨ë¡œ ì¦ê°€: ê³¼ê²©ì„± 2ì¸ ë²”ì£„ì˜ ê²½ìš° í•˜ìœ„ 10ê°œ ì£¼ì—ì„œë„ ë‘ ë°° ì¦ê°€í–ˆì§€ë§Œ, ìƒìœ„ 10ê°œ ì£¼ì—ì„œëŠ” ì „ë…„ë„ ëŒ€ë¹„ 171% ì¦ê°€í–ˆë„¤ìš”. ì½”ë¡œë‚˜19ê°€ ì‹¬í–ˆë˜ ì§€ì—­ì—ì„œëŠ” ê³¼ê²©ì„±ì´ ë‚®ì€ ë²”ì£„ì™€ ë†’ì€ ë²”ì£„ê°€ ê³ ë£¨ ì•„ì‹œì•„ì¸ì„ ëŒ€ìƒìœ¼ë¡œ í–‰í•´ì¡Œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì–´ìš”.
    ''')
    
    st.write("ì½”ë¡œë‚˜19 ì‚¬ë§ì í•˜ìœ„ 10ê°œ ì£¼")
    st.write(fig_off_asian_bottom)
    st.write(fig_loc_asian_bottom)
    
    #ë²”ì£„ ì¥ì†Œ ê³µê°œì„± ë¹„êµ
    st.info('''
    * ì½”ë¡œë‚˜19 ì‹¬í•œ ì§€ì—­ì´ ë²”ì£„ ì¥ì†Œì˜ ê³µê°œì„± ë” ë†’ì•„: ìš°ì„  ê³µê°œì„±ì´ 5ì¸ ì¥ì†Œì—ì„œ ë°œìƒí•œ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ëŠ” ì‚¬ë§ììˆ˜ê°€ ê°€ì¥ ë§ì€ 10ê°œì£¼ì—ì„œ ì¦ê°€í•œ ë°˜ë©´, ì‚¬ë§ììˆ˜ê°€ ê°€ì¥ ì ì€ 10ê°œì£¼ì—ì„œëŠ” ì˜¤íˆë ¤ ê°ì†Œí–ˆì–´ìš”. ê³µê°œì„± 4ì¸ ì¥ì†Œì—ì„œ ì¼ì–´ë‚œ í˜ì˜¤ ë²”ì£„ì˜ ì¦ê°€ìœ¨ì€ ìƒìœ„ 10ê°œ ì£¼ì—ì„œëŠ” ì „ë…„ë„ ëŒ€ë¹„ 80%, í•˜ìœ„ 10ê°œ ì£¼ì—ì„œëŠ” 16%ì˜€ê³ ìš”. ì½”ë¡œë‚˜19 ì‚¬ë§ìê°€ ë§ì€ ì£¼ì—ì„œ ë” ê³µê°œì„± ë†’ì€ í˜ì˜¤ ë²”ì£„ê°€ ì´ì „ì— ë¹„í•´ ë§ì´ ë°œìƒí–ˆìŒì„ ì•Œ ìˆ˜ ìˆì–´ìš”ğŸ§‘â€âš–ï¸
    ''')


    st.markdown("""
    ##### âœ‹ì ê¹! ì—¬ê¸°ê¹Œì§€ ì •ë¦¬ âœ‹
    * ë¯¸êµ­ ì „ì—­ì— ì´ì–´ ì½”ë¡œë‚˜19 ì‚¬ë§ìê°€ ë§ì•˜ë˜ 10ê°œ ì£¼ì™€ ê·¸ë ‡ì§€ ì•Šì€ 10ê°œ ì£¼ë¥¼ ë¹„êµí•´ë´¤ëŠ”ë°ìš”, ìƒìœ„ 10ê°œ ì£¼ì—ì„œ ë°œìƒí•œ ë²”ì£„ì˜ ê³¼ê²©ì„±ì´ í•˜ìœ„ 10ê°œ ì£¼ë³´ë‹¤ ë”ìš± ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
    * ë²”ì£„ ì¥ì†Œì˜ ê³µê°œì„± ë˜í•œ, ì½”ë¡œë‚˜19ë¥¼ ì „í›„ë¡œ ê·¸ í”¼í•´ê°€ ì‹¬í–ˆë˜ ì§€ì—­ì—ì„œ ë”ìš± ì¦ê°€í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆì—ˆì–´ìš”. 
    * ê²°ë¡ ì ìœ¼ë¡œ ì½”ë¡œë‚˜19ê°€ ì‹¬í–ˆë˜ ì£¼ì˜ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ì–‘ìƒì´, 2019ë…„ê³¼ 2020ë…„ ì‚¬ì´ ë”ìš± ìœ ì˜ë¯¸í•˜ê²Œ ë³€í™”í–ˆìŒì„ ì•Œ ìˆ˜ ìˆì–´ìš”. 
    ì´ë¥¼ í†µí•´, ì½”ë¡œë‚˜ 19ì˜ ë°œìƒê³¼ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì˜ ì‹¬ê°ì„± ì‚¬ì´ ê°•í•œ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ğŸ“ŠğŸ–Šï¸
    """)

    st.markdown('''
    -----------
                ''')


elif add_radio == "ğŸ“ˆ íŠ¸ëŸ¼í”„ ë“±ì¥! í˜ì˜¤ ë²”ì£„ë„ ìƒìŠ¹?":

  # section 4: ì—°ì„¤ë¬¸ íŠ¸ë¦¬ë§µ
  st.markdown('''
  ## ğŸ“ˆ íŠ¸ëŸ¼í”„ ë“±ì¥! í˜ì˜¤ ë²”ì£„ë„ ìƒìŠ¹?
              ''')


  st.warning('''
  * íŠ¸ëŸ¼í”„ ì§‘ê¶Œ ì‹œê¸°, ë°”ì´ë“  ì§‘ê¶Œ ì‹œê¸° êµ­ì • ì—°ì„¤(State of the Union Speech) í‚¤ì›Œë“œ ë¶„ì„ì„ í•´ë´¤ì–´ìš”.
  * 1ë…„ì— í•œ ë²ˆ ìˆëŠ” êµ­ì •ì—°ì„¤ì€ ëŒ€í†µë ¹ì´ ì§ì ‘ êµ­ê°€ ìƒí™©ê³¼ ì •ì±… ê¸°ì¡°ë¥¼ ì„¤ëª…í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ë‹´í™”ì—ìš”.
  * ë³´ë¼ìƒ‰ íŠ¸ë¦¬ë§µì€ ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œë¥¼ ë¹ˆë„ìˆ˜ëŒ€ë¡œ ê·¸ë¦° ê²ƒì´ê³ , ì•„ë˜ì˜ íŠ¸ë¦¬ë§µì€ ê·¸ì¤‘ì—ì„œë„ í˜ì˜¤ ë²”ì£„ ê´€ë ¨ ë‹¨ì–´ë“¤ì„ ëª¨ì•„ë†“ì€ ê²ƒì´ì—ìš”! 
  ''')


  ##st.error("""
  ##hate_words_list = ['isis', 'islamic', 'terrorist', 'asian', 'border', 'race', 'racism', 'african-american', 'immigration', 'china', 'threat']
  ##"""
  ##)

  #*stopwords ì—…ë°ì´íŠ¸
  #words filtered
  from nltk.corpus import stopwords
  stop_words = set(stopwords.words('english'))
  stop_words.update(['.', ',', '"', "'", '?', '!',"''",'``', '', '', ':', ';', 'â€™', '(', ')','`','[', ']',
  '--','â€“', 'â€œ', 'â€', '{', '}','_', "'\\n", "\n", "â€”", '%', '#', '###', 'u', 'wa', '$', 'america', 'american', 
  'americans', 'people', 'year', 'ha', 'also', 'tonight']) #ë§¤ë…„ ë°˜ë³µë˜ëŠ” ì˜ë¡€ì  ë‹¨ì–´ë“¤ì€ ì œì™¸.


  @st.cache(suppress_st_warning=True)
  def speech_keywords_counter(url):
      doc = ""
      with urllib.request.urlopen(url) as url:
          doc = url.read()

      soup = BeautifulSoup(doc, "html.parser")
      speech = soup.find_all("p", class_="paragraph inline-placeholder")


      sentences = []
      for i in range(len(speech)):
          sentences.append(speech[i].text.strip())

      lemma = nltk.wordnet.WordNetLemmatizer()
      speech_tokens = []
      for sentence in sentences:
          speech_tokens.append(nltk.word_tokenize(sentence))

      speech_lemma = []

      for token in speech_tokens :
          for tok in token:
              speech_lemma.append(lemma.lemmatize(tok))

      #stopwords ìœ„ì— í•´ë‘        
      words_filtered = [word.lower() for word in speech_lemma if word.lower() not in stop_words]
      speech_cnt = Counter(words_filtered)

      return speech_cnt

  # ì „ì²´ ë¦¬ìŠ¤íŠ¸ + í˜ì˜¤ ë²”ì£„ ê´€ë ¨ ë‹¨ì–´ë“¤ ë¹ˆë„ìˆ˜ ì„¸ëŠ” ë¦¬ìŠ¤íŠ¸ ë§Œë“œëŠ” í•¨ìˆ˜ ì¶”ê°€
  @st.cache(allow_output_mutation=True)
  def count_words_total(counter):
      hate_words_list = ['isis', 'islamic', 'terrorist', 'asian', 'border', 'race', 'racism', 'african-american', 'immigration', 'china', 'threat']
      hate_words_dict = {}

      counter_df = pd.DataFrame(counter.most_common(), columns = ['word', 'count'])
      for w in counter_df['word']:
          if w in hate_words_list:
              hate_words_dict[w] = len(counter_df[counter_df['word'] == w])

      hate_words = list(hate_words_dict.keys())
      hate_words_count = list(hate_words_dict.values())

      counter_df_hate = pd.DataFrame({'word': hate_words, 'count': hate_words_count, 'type': hate_words_count})
      counter_df_hate['type'] = 'hate crime word'

      return counter_df_hate

  ############### 2017 #################
  url_2017 = "https://edition.cnn.com/2017/02/28/politics/donald-trump-speech-transcript-full-text/index.html"
  word_2017 = pd.DataFrame(speech_keywords_counter(url_2017).most_common(70), columns = ['word', 'count'])
  hate_2017 = count_words_total(speech_keywords_counter(url_2017))

  ##############2018##############
  url_2018 = "https://edition.cnn.com/2018/01/30/politics/2018-state-of-the-union-transcript/index.html"
  word_2018 = pd.DataFrame(speech_keywords_counter(url_2018).most_common(70), columns = ['word', 'count'])
  hate_2018 = count_words_total(speech_keywords_counter(url_2018))

  ##############2019##############
  url_2019 = "https://edition.cnn.com/2019/02/05/politics/donald-trump-state-of-the-union-2019-transcript/index.html"
  word_2019 = pd.DataFrame(speech_keywords_counter(url_2019).most_common(70), columns = ['word', 'count'])
  hate_2019= count_words_total(speech_keywords_counter(url_2019))

  ##############2020##############
  url_2020 = "https://edition.cnn.com/2020/02/04/politics/trump-2020-state-of-the-union-address/index.html"
  word_2020 = pd.DataFrame(speech_keywords_counter(url_2020).most_common(70), columns = ['word', 'count'])
  hate_2020 = count_words_total(speech_keywords_counter(url_2020))

  ###################2021################# ì–˜ë§Œ ë§í¬ê°€ ë‹¬ë¼ì„œ ë‹¤ë¥´ê²Œ í•¨..
  url_2021 = "https://www.whitehouse.gov/briefing-room/speeches-remarks/2022/03/01/remarks-of-president-joe-biden-state-of-the-union-address-as-delivered/"
  doc_2021 = ""
  with urllib.request.urlopen(url_2021) as url:
      doc_2021 = url.read()

  soup = BeautifulSoup(doc_2021, "html.parser")

  s_2021 = soup.find_all("p")

  sentences_2021 = []
  for i in range(len(s_2021)):
      sentences_2021.append(s_2021[i].text.strip().replace('\xa0', ''))

  #sentences_2021

  lemma = nltk.wordnet.WordNetLemmatizer()
  s_2021_tokens = []
  for sentence in sentences_2021:
      s_2021_tokens.append(nltk.word_tokenize(sentence))

  s_2021_lemma = []

  for token in s_2021_tokens :
      for tok in token:
          s_2021_lemma.append(lemma.lemmatize(tok))

  #stopwords ìœ„ì— í•´ë‘        
  words_filtered_2021 = [word.lower() for word in s_2021_lemma if word.lower() not in stop_words]

  s_2021_cnt = Counter(words_filtered_2021)
  word_2021 = pd.DataFrame(s_2021_cnt.most_common(70), columns = ['word', 'count'])
  hate_2021 = count_words_total(s_2021_cnt)

  ##############2022##############
  url_2022 = "https://edition.cnn.com/2022/03/01/politics/biden-state-of-the-union-2022-transcript/index.html"
  word_2022 = pd.DataFrame(speech_keywords_counter(url_2022).most_common(70), columns = ['word', 'count'])
  hate_2022 = count_words_total(speech_keywords_counter(url_2022))


  select_year = st.selectbox('í™•ì¸í•  ì—°ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”', ('2017', '2018', '2019', '2020', '2021', '2022'))

  ## *íŠ¸ë¦¬ë§µ ê·¸ë¦¬ëŠ” í•¨ìˆ˜!
  #from plotly.subplots import make_subplots

  @st.cache
  def draw_treemap(word_df):
      fig = px.treemap(
          word_df, path=[px.Constant("total"), 'word'],
          values = 'count',
          color = 'count',
          color_continuous_scale='Purples',
          color_continuous_midpoint = 0, title='State of the Union Speech Keywords'
      )
      fig.update_traces(root_color="lightgrey")
      fig.update_layout(font_size=15, margin = dict(t=50, l=25, r=25, b=25))

      return fig

  @st.cache
  def draw_treemap_hate(word_df):
      fig = px.treemap(
          word_df, path=[px.Constant("total"),  'word'],
          values = 'count',
          color_discrete_map= {'word' : 'red'},
          color_continuous_midpoint = 0, title='Hate Crime Keywords'
      )
      fig.update_traces(root_color="lightgrey")
      fig.update_layout(font_size=20, margin = dict(t=50, l=25, r=25, b=25))

      return fig

  #color_continuous_midpoint

  if select_year == '2017':
      st.plotly_chart(draw_treemap(word_2017), use_container_width=True)
      st.plotly_chart(draw_treemap_hate(hate_2017), use_container_width=True)
  elif select_year == '2018':
      st.plotly_chart(draw_treemap(word_2018))
      st.plotly_chart(draw_treemap_hate(hate_2018))
  elif select_year == '2019':
      st.plotly_chart(draw_treemap(word_2019))
      st.plotly_chart(draw_treemap_hate(hate_2019))
  elif select_year == '2020':
      st.plotly_chart(draw_treemap(word_2020))
      st.plotly_chart(draw_treemap_hate(hate_2020))
  elif select_year == '2021':
      st.plotly_chart(draw_treemap(word_2021))
      st.plotly_chart(draw_treemap_hate(hate_2021))
  elif select_year == '2022':
      st.plotly_chart(draw_treemap(word_2022))
      st.plotly_chart(draw_treemap_hate(hate_2022))


  st.info('''
  * 2016ë…„ë¶€í„° 2022ë…„, êµ­ì • ì—°ì„¤ ë¹„êµí•´ë³´ë‹ˆ: ë¹ˆë„ìˆ˜ë¥¼ ë¹„êµí•´ë³´ë‹ˆ, íŠ¸ëŸ¼í”„ ì‹œê¸°ì—ëŠ” race, islamic, isis, African-Americanê³¼ ê°™ì€ ì§ì ‘ì ì¸ ì¸ì¢… ë° ë¯¼ì¡± ì–¸ê¸‰ì´ ë§ì•˜ë˜ ë°˜ë©´ ë°”ì´ë“  ì‹œê¸°ì—ëŠ” ê·¸ëŸ° í‚¤ì›Œë“œê°€ ë“±ì¥í•˜ì§€ ì•Šê³  immigration, threat ë“±ì˜ ë‹¨ì–´ë§Œ ê³µí†µì ìœ¼ë¡œ ì—°ì„¤ì— ì‚¬ìš©ëì–´ìš”. 
  * ì´ìŠ¬ëŒ ê´€ë ¨ ì–¸ê¸‰ì´ íŠ¹íˆ ë§ì•„: íŠ¸ëŸ¼í”„ ì‹œê¸° êµ­ì •ì—°ì„¤ì—ëŠ” ë‹¤ë¥¸ ê²ƒë³´ë‹¤ë„ terroristë¼ëŠ” ë‹¨ì–´ì™€ ì´ìŠ¬ëŒ ê´€ë ¨ ë‹¨ì–´ì¸ ISIS, Islamicì´ ìì£¼ í•¨ê»˜ ë“±ì¥í–ˆì–´ìš”. 2020ë…„ê¹Œì§€ ë¬´ìŠ¬ë¦¼ í˜ì˜¤ ë²”ì£„ê°€ ê¾¸ì¤€íˆ ë¹„ì¤‘ì„ ì°¨ì§€í–ˆë˜ ê²ƒê³¼ ë¬´ê´€í•˜ì§€ ì•Šì•„ë³´ì…ë‹ˆë‹¤. 
  ë°”ì´ë“  ì‹œê¸°ì—ë„ terroristë¼ëŠ” ë‹¨ì–´ëŠ” êµ­ì • ì—°ì„¤ì— ì‚¬ìš©ëì§€ë§Œ, íŠ¹ì • ì¸ì¢…ê³¼ ë¯¼ì¡±ì„ ì½• ì§‘ì–´ ì–¸ê¸‰í•˜ì§€ëŠ” ì•Šì•˜ë‹¤ëŠ” ì°¨ì´ì ì´ ìˆì–´ìš”.
  ''')


  st.markdown('''
  ##### ğŸ’¬ë§ˆë¬´ë¦¬í•˜ëŠ” ë§ğŸ’¬
  ğŸ“ íŠ¸ëŸ¼í”„ ë‹¹ì„  ì‹œê¸°ë¥¼ ê¸°ì ìœ¼ë¡œ ì „ì²´ í˜ì˜¤ ë²”ì£„ê°€ ì¦ê°€í–ˆìŒì€ ë¬¼ë¡ ,
  íŠ¸ëŸ¼í”„ ì§‘ê¶Œ ì‹œê¸°ì—ëŠ” ëŒ€í†µë ¹ êµ­ì •ì—°ì„¤ì—ì„œë„ ì¸ì¢… ê´€ë ¨ ë¬¸ì œê°€ ë”ìš± ìì£¼ ë“±ì¥í–ˆì–´ìš”.
  ë˜í•œ íŠ¹ì • ì¸ì¢…ì— ê´€í•œ ë¶€ì •ì ì¸ ê°ì •ì„ ìœ ë°œí•  ìˆ˜ ìˆëŠ” ë‹¨ì–´ë„ ë°”ì´ë“  ì‹œê¸°ì— ë¹„í•´ í›¨ì”¬ ìì£¼ ë“±ì¥í–ˆë‹µë‹ˆë‹¤.
  ì¦‰ íŠ¸ëŸ¼í”„ì˜ ë“±ì¥ê³¼ ì „ë°˜ì ì¸ í˜ì˜¤ ë²”ì£„ì˜ ì¦ê°€ê°€ ë‚˜ë¦„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì§€ë‹ˆê³  ìˆë‹¤ê³  ì •ë¦¬í•´ë³¼ ìˆ˜ ìˆê² ì–´ìš”!

  ğŸ“ ì½”ë¡œë‚˜19ê°€ ì°½ê¶í•œ ì´í›„, ë¯¸êµ­ ë‚´ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì˜ ì‹¬ê°ì„±ì€ ê·¸ì „ê³¼ ë¹„êµí•´ ì‹¬í™”ëìŠµë‹ˆë‹¤. 
  íŠ¹íˆ ì½”ë¡œë‚˜19ê°€ ìƒë¥™í•œ ì‹œê¸° ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ìˆ˜ëŠ” ê·¹ì— ë‹¬í–ˆê³ , ê³¼ê²©ì„±ì€ ë¬¼ë¡  ê³µê°œì ì¸ ì¥ì†Œì—ì„œ ë²Œì–´ì§€ëŠ” ë²”ì£„ë„ ìœ ì˜ë¯¸í•˜ê²Œ ì¦ê°€í–ˆì–´ìš”â¬†ï¸

  ğŸ“ ì½”ë¡œë‚˜19ì™€ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì˜ ê´€ê³„ëŠ” ì½”ë¡œë‚˜19 ì‚¬ë§ìê°€ ë§ì•˜ë˜ 10ê°œ ì£¼ì™€ ì‚¬ë§ìê°€ ì ì—ˆë˜ 10ê°œ ì£¼ì˜ ë¹„êµë¥¼ í†µí•´ ê°€ì¥ ë¶„ëª…íˆ ë³¼ ìˆ˜ ìˆì—ˆì–´ìš”. 
  ì‚¬ë§ì ìˆ˜ê°€ ë§ì€ ì§€ì—­ì¼ìˆ˜ë¡ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ ìˆ˜, ë²”ì£„ì˜ ê³¼ê²©ì„±, ê³µê²©ì„±ì´ 2020ë…„ ë” ë†’ì€ ë¹„ìœ¨ë¡œ ì¦ê°€í–ˆê³ ,
   ë‚®ì€ ì§€ì—­ì¼ìˆ˜ë¡ ì½”ë¡œë‚˜19ì˜ ë“±ì¥ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ë²”ì£„ ì–‘ìƒì´ ìœ ì§€ë˜ê±°ë‚˜ ì˜¤íˆë ¤ í•˜ë½í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹µë‹ˆë‹¤.
   ìš”ì»¨ëŒ€ ì½”ë¡œë‚˜19ì˜ ë“±ì¥ê³¼ ì•„ì‹œì•„ì¸ í˜ì˜¤ ë²”ì£„ì˜ ì‹¬ê°ì„±ì€ ì •ì˜ ê´€ê³„(â•)ì— ìˆë‹¤ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
          ''')

